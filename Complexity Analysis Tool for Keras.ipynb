{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operational Intensity Analysis Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.applications import VGG16, MobileNet, Xception, ResNet50, InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_kernel_size(layer):\n",
    "    layer_type = layer.__class__.__name__\n",
    "    if 'Conv2D' in layer_type or 'Dense' in layer_type:\n",
    "        weights = layer.get_weights()\n",
    "        return weights[0].shape\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getFLOPS(layer, kernel, output):\n",
    "    # For Xception\n",
    "    if \"Separable\" in layer:\n",
    "        return np.prod(output) * (np.prod(kernel[:-2]) + kernel[-2])\n",
    "    # For MobileNet\n",
    "    elif \"Depthwise\" in layer:\n",
    "        return np.prod(output) * np.prod(kernel[:-2])\n",
    "    # Regular Convolution\n",
    "    elif \"Conv2D\" in layer or \"Dense\" in layer:\n",
    "        return np.prod(output) * np.prod(kernel[:-1])\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def intensity(model):\n",
    "    print('Layer Name | Layer Type | Kernel Size | Kernel Mem | Output Size | Output Mem | FLOPS')\n",
    "    print('--- | --- | --- | --- | --- | --- | ---')\n",
    "    sum_kernel_mem = 0\n",
    "    sum_output_mem = 0\n",
    "    sum_flops = 0\n",
    "    for l in model.layers:\n",
    "        layer_type = l.__class__.__name__\n",
    "        kernel_size = get_kernel_size(l)\n",
    "        kernel_mem = np.prod(kernel_size)\n",
    "        output_size = l.output_shape[1:]\n",
    "        output_mem = np.prod(output_size)\n",
    "        flops = getFLOPS(layer_type, kernel_size, output_size)\n",
    "        print(l.name, '|', layer_type, '|', \n",
    "              kernel_size, '|', \"{:,}\".format(kernel_mem), '|', \n",
    "              output_size, '|', \"{:,}\".format(output_mem), '|', \n",
    "              \"{:,}\".format(flops))\n",
    "        sum_kernel_mem += kernel_mem\n",
    "        sum_output_mem += output_mem\n",
    "        sum_flops += flops\n",
    "    print('- | - | - | - | - | - | -')\n",
    "    print('- | - | - | Kernel Mem (Total) | - | Output Mem (Total) | FLOPS (Total)')\n",
    "    print('Summary | - | - |', \n",
    "          \"{:,}\".format(sum_kernel_mem), '| - |', \n",
    "          \"{:,}\".format(sum_output_mem), '|', \n",
    "          \"{:,}\".format(sum_flops))\n",
    "    print('\\n----------------------\\n')\n",
    "    print('Model Name: %s' % model.name)\n",
    "    print('Overall FLOPS: %.f MFLOPS' % (sum_flops/1000/1000))\n",
    "    print('Overall Params: %.f MParams' % ((sum_kernel_mem + sum_output_mem)/1024/1024))\n",
    "    # Default dtype is float32 (4Byte)\n",
    "    op_intensity = sum_flops / ((sum_kernel_mem + sum_output_mem) * 4)\n",
    "    print('Operational Intensity = %.f FLOPS/Byte' % op_intensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"MobileNet v2 models for Keras.\n",
    "\n",
    "# Reference\n",
    "- [Inverted Residuals and Linear Bottlenecks Mobile Networks for\n",
    "   Classification, Detection and Segmentation]\n",
    "   (https://arxiv.org/abs/1801.04381)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, GlobalAveragePooling2D, Dropout\n",
    "from keras.layers import Activation, BatchNormalization, add, Reshape\n",
    "from keras.applications.mobilenet import relu6, DepthwiseConv2D\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "def _conv_block(inputs, filters, kernel, strides):\n",
    "    \"\"\"Convolution Block\n",
    "    This function defines a 2D convolution operation with BN and relu6.\n",
    "\n",
    "    # Arguments\n",
    "        inputs: Tensor, input tensor of conv layer.\n",
    "        filters: Integer, the dimensionality of the output space.\n",
    "        kernel: An integer or tuple/list of 2 integers, specifying the\n",
    "            width and height of the 2D convolution window.\n",
    "        strides: An integer or tuple/list of 2 integers,\n",
    "            specifying the strides of the convolution along the width and height.\n",
    "            Can be a single integer to specify the same value for\n",
    "            all spatial dimensions.\n",
    "\n",
    "    # Returns\n",
    "        Output tensor.\n",
    "    \"\"\"\n",
    "\n",
    "    channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
    "\n",
    "    x = Conv2D(filters, kernel, padding='same', strides=strides)(inputs)\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    "    return Activation(relu6)(x)\n",
    "\n",
    "\n",
    "def _bottleneck(inputs, filters, kernel, t, s, r=False):\n",
    "    \"\"\"Bottleneck\n",
    "    This function defines a basic bottleneck structure.\n",
    "\n",
    "    # Arguments\n",
    "        inputs: Tensor, input tensor of conv layer.\n",
    "        filters: Integer, the dimensionality of the output space.\n",
    "        kernel: An integer or tuple/list of 2 integers, specifying the\n",
    "            width and height of the 2D convolution window.\n",
    "        t: Integer, expansion factor.\n",
    "            t is always applied to the input size.\n",
    "        s: An integer or tuple/list of 2 integers,specifying the strides\n",
    "            of the convolution along the width and height.Can be a single\n",
    "            integer to specify the same value for all spatial dimensions.\n",
    "        r: Boolean, Whether to use the residuals.\n",
    "\n",
    "    # Returns\n",
    "        Output tensor.\n",
    "    \"\"\"\n",
    "\n",
    "    channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
    "    tchannel = K.int_shape(inputs)[channel_axis] * t\n",
    "\n",
    "    x = _conv_block(inputs, tchannel, (1, 1), (1, 1))\n",
    "\n",
    "    x = DepthwiseConv2D(kernel, strides=(s, s), depth_multiplier=1, padding='same')(x)\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    "    x = Activation(relu6)(x)\n",
    "\n",
    "    x = Conv2D(filters, (1, 1), strides=(1, 1), padding='same')(x)\n",
    "    x = BatchNormalization(axis=channel_axis)(x)\n",
    "\n",
    "    if r:\n",
    "        x = add([x, inputs])\n",
    "    return x\n",
    "\n",
    "\n",
    "def _inverted_residual_block(inputs, filters, kernel, t, strides, n):\n",
    "    \"\"\"Inverted Residual Block\n",
    "    This function defines a sequence of 1 or more identical layers.\n",
    "\n",
    "    # Arguments\n",
    "        inputs: Tensor, input tensor of conv layer.\n",
    "        filters: Integer, the dimensionality of the output space.\n",
    "        kernel: An integer or tuple/list of 2 integers, specifying the\n",
    "            width and height of the 2D convolution window.\n",
    "        t: Integer, expansion factor.\n",
    "            t is always applied to the input size.\n",
    "        s: An integer or tuple/list of 2 integers,specifying the strides\n",
    "            of the convolution along the width and height.Can be a single\n",
    "            integer to specify the same value for all spatial dimensions.\n",
    "        n: Integer, layer repeat times.\n",
    "    # Returns\n",
    "        Output tensor.\n",
    "    \"\"\"\n",
    "\n",
    "    x = _bottleneck(inputs, filters, kernel, t, strides)\n",
    "\n",
    "    for i in range(1, n):\n",
    "        x = _bottleneck(x, filters, kernel, t, 1, True)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def MobileNetv2(input_shape, k):\n",
    "    \"\"\"MobileNetv2\n",
    "    This function defines a MobileNetv2 architectures.\n",
    "\n",
    "    # Arguments\n",
    "        input_shape: An integer or tuple/list of 3 integers, shape\n",
    "            of input tensor.\n",
    "        k: Integer, number of classes.\n",
    "    # Returns\n",
    "        MobileNetv2 model.\n",
    "    \"\"\"\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = _conv_block(inputs, 32, (3, 3), strides=(2, 2))\n",
    "\n",
    "    x = _inverted_residual_block(x, 16, (3, 3), t=1, strides=1, n=1)\n",
    "    x = _inverted_residual_block(x, 24, (3, 3), t=6, strides=2, n=2)\n",
    "    x = _inverted_residual_block(x, 32, (3, 3), t=6, strides=2, n=3)\n",
    "    x = _inverted_residual_block(x, 64, (3, 3), t=6, strides=2, n=4)\n",
    "    x = _inverted_residual_block(x, 96, (3, 3), t=6, strides=1, n=3)\n",
    "    x = _inverted_residual_block(x, 160, (3, 3), t=6, strides=2, n=3)\n",
    "    x = _inverted_residual_block(x, 320, (3, 3), t=6, strides=1, n=1)\n",
    "\n",
    "    x = _conv_block(x, 1280, (1, 1), strides=(1, 1))\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Reshape((1, 1, 1280))(x)\n",
    "    x = Dropout(0.3, name='Dropout')(x)\n",
    "    x = Conv2D(k, (1, 1), padding='same')(x)\n",
    "\n",
    "    x = Activation('softmax', name='softmax')(x)\n",
    "    output = Reshape((k,))(x)\n",
    "\n",
    "    model = Model(inputs, output)\n",
    "    plot_model(model, to_file='MobileNetv2.png', show_shapes=True)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer Name | Layer Type | Kernel Size | Kernel Mem | Output Size | Output Mem | FLOPS\n",
      "--- | --- | --- | --- | --- | --- | ---\n",
      "input_10 | InputLayer | 0 | 0 | (224, 224, 3) | 150,528 | 0\n",
      "conv2d_300 | Conv2D | (3, 3, 3, 32) | 864 | (112, 112, 32) | 401,408 | 10,838,016\n",
      "batch_normalization_348 | BatchNormalization | 0 | 0 | (112, 112, 32) | 401,408 | 0\n",
      "activation_346 | Activation | 0 | 0 | (112, 112, 32) | 401,408 | 0\n",
      "conv2d_301 | Conv2D | (1, 1, 32, 32) | 1,024 | (112, 112, 32) | 401,408 | 12,845,056\n",
      "batch_normalization_349 | BatchNormalization | 0 | 0 | (112, 112, 32) | 401,408 | 0\n",
      "activation_347 | Activation | 0 | 0 | (112, 112, 32) | 401,408 | 0\n",
      "depthwise_conv2d_52 | DepthwiseConv2D | (3, 3, 32, 1) | 288 | (112, 112, 32) | 401,408 | 3,612,672\n",
      "batch_normalization_350 | BatchNormalization | 0 | 0 | (112, 112, 32) | 401,408 | 0\n",
      "activation_348 | Activation | 0 | 0 | (112, 112, 32) | 401,408 | 0\n",
      "conv2d_302 | Conv2D | (1, 1, 32, 16) | 512 | (112, 112, 16) | 200,704 | 6,422,528\n",
      "batch_normalization_351 | BatchNormalization | 0 | 0 | (112, 112, 16) | 200,704 | 0\n",
      "conv2d_303 | Conv2D | (1, 1, 16, 96) | 1,536 | (112, 112, 96) | 1,204,224 | 19,267,584\n",
      "batch_normalization_352 | BatchNormalization | 0 | 0 | (112, 112, 96) | 1,204,224 | 0\n",
      "activation_349 | Activation | 0 | 0 | (112, 112, 96) | 1,204,224 | 0\n",
      "depthwise_conv2d_53 | DepthwiseConv2D | (3, 3, 96, 1) | 864 | (56, 56, 96) | 301,056 | 2,709,504\n",
      "batch_normalization_353 | BatchNormalization | 0 | 0 | (56, 56, 96) | 301,056 | 0\n",
      "activation_350 | Activation | 0 | 0 | (56, 56, 96) | 301,056 | 0\n",
      "conv2d_304 | Conv2D | (1, 1, 96, 24) | 2,304 | (56, 56, 24) | 75,264 | 7,225,344\n",
      "batch_normalization_354 | BatchNormalization | 0 | 0 | (56, 56, 24) | 75,264 | 0\n",
      "conv2d_305 | Conv2D | (1, 1, 24, 144) | 3,456 | (56, 56, 144) | 451,584 | 10,838,016\n",
      "batch_normalization_355 | BatchNormalization | 0 | 0 | (56, 56, 144) | 451,584 | 0\n",
      "activation_351 | Activation | 0 | 0 | (56, 56, 144) | 451,584 | 0\n",
      "depthwise_conv2d_54 | DepthwiseConv2D | (3, 3, 144, 1) | 1,296 | (56, 56, 144) | 451,584 | 4,064,256\n",
      "batch_normalization_356 | BatchNormalization | 0 | 0 | (56, 56, 144) | 451,584 | 0\n",
      "activation_352 | Activation | 0 | 0 | (56, 56, 144) | 451,584 | 0\n",
      "conv2d_306 | Conv2D | (1, 1, 144, 24) | 3,456 | (56, 56, 24) | 75,264 | 10,838,016\n",
      "batch_normalization_357 | BatchNormalization | 0 | 0 | (56, 56, 24) | 75,264 | 0\n",
      "add_47 | Add | 0 | 0 | (56, 56, 24) | 75,264 | 0\n",
      "conv2d_307 | Conv2D | (1, 1, 24, 144) | 3,456 | (56, 56, 144) | 451,584 | 10,838,016\n",
      "batch_normalization_358 | BatchNormalization | 0 | 0 | (56, 56, 144) | 451,584 | 0\n",
      "activation_353 | Activation | 0 | 0 | (56, 56, 144) | 451,584 | 0\n",
      "depthwise_conv2d_55 | DepthwiseConv2D | (3, 3, 144, 1) | 1,296 | (28, 28, 144) | 112,896 | 1,016,064\n",
      "batch_normalization_359 | BatchNormalization | 0 | 0 | (28, 28, 144) | 112,896 | 0\n",
      "activation_354 | Activation | 0 | 0 | (28, 28, 144) | 112,896 | 0\n",
      "conv2d_308 | Conv2D | (1, 1, 144, 32) | 4,608 | (28, 28, 32) | 25,088 | 3,612,672\n",
      "batch_normalization_360 | BatchNormalization | 0 | 0 | (28, 28, 32) | 25,088 | 0\n",
      "conv2d_309 | Conv2D | (1, 1, 32, 192) | 6,144 | (28, 28, 192) | 150,528 | 4,816,896\n",
      "batch_normalization_361 | BatchNormalization | 0 | 0 | (28, 28, 192) | 150,528 | 0\n",
      "activation_355 | Activation | 0 | 0 | (28, 28, 192) | 150,528 | 0\n",
      "depthwise_conv2d_56 | DepthwiseConv2D | (3, 3, 192, 1) | 1,728 | (28, 28, 192) | 150,528 | 1,354,752\n",
      "batch_normalization_362 | BatchNormalization | 0 | 0 | (28, 28, 192) | 150,528 | 0\n",
      "activation_356 | Activation | 0 | 0 | (28, 28, 192) | 150,528 | 0\n",
      "conv2d_310 | Conv2D | (1, 1, 192, 32) | 6,144 | (28, 28, 32) | 25,088 | 4,816,896\n",
      "batch_normalization_363 | BatchNormalization | 0 | 0 | (28, 28, 32) | 25,088 | 0\n",
      "add_48 | Add | 0 | 0 | (28, 28, 32) | 25,088 | 0\n",
      "conv2d_311 | Conv2D | (1, 1, 32, 192) | 6,144 | (28, 28, 192) | 150,528 | 4,816,896\n",
      "batch_normalization_364 | BatchNormalization | 0 | 0 | (28, 28, 192) | 150,528 | 0\n",
      "activation_357 | Activation | 0 | 0 | (28, 28, 192) | 150,528 | 0\n",
      "depthwise_conv2d_57 | DepthwiseConv2D | (3, 3, 192, 1) | 1,728 | (28, 28, 192) | 150,528 | 1,354,752\n",
      "batch_normalization_365 | BatchNormalization | 0 | 0 | (28, 28, 192) | 150,528 | 0\n",
      "activation_358 | Activation | 0 | 0 | (28, 28, 192) | 150,528 | 0\n",
      "conv2d_312 | Conv2D | (1, 1, 192, 32) | 6,144 | (28, 28, 32) | 25,088 | 4,816,896\n",
      "batch_normalization_366 | BatchNormalization | 0 | 0 | (28, 28, 32) | 25,088 | 0\n",
      "add_49 | Add | 0 | 0 | (28, 28, 32) | 25,088 | 0\n",
      "conv2d_313 | Conv2D | (1, 1, 32, 192) | 6,144 | (28, 28, 192) | 150,528 | 4,816,896\n",
      "batch_normalization_367 | BatchNormalization | 0 | 0 | (28, 28, 192) | 150,528 | 0\n",
      "activation_359 | Activation | 0 | 0 | (28, 28, 192) | 150,528 | 0\n",
      "depthwise_conv2d_58 | DepthwiseConv2D | (3, 3, 192, 1) | 1,728 | (14, 14, 192) | 37,632 | 338,688\n",
      "batch_normalization_368 | BatchNormalization | 0 | 0 | (14, 14, 192) | 37,632 | 0\n",
      "activation_360 | Activation | 0 | 0 | (14, 14, 192) | 37,632 | 0\n",
      "conv2d_314 | Conv2D | (1, 1, 192, 64) | 12,288 | (14, 14, 64) | 12,544 | 2,408,448\n",
      "batch_normalization_369 | BatchNormalization | 0 | 0 | (14, 14, 64) | 12,544 | 0\n",
      "conv2d_315 | Conv2D | (1, 1, 64, 384) | 24,576 | (14, 14, 384) | 75,264 | 4,816,896\n",
      "batch_normalization_370 | BatchNormalization | 0 | 0 | (14, 14, 384) | 75,264 | 0\n",
      "activation_361 | Activation | 0 | 0 | (14, 14, 384) | 75,264 | 0\n",
      "depthwise_conv2d_59 | DepthwiseConv2D | (3, 3, 384, 1) | 3,456 | (14, 14, 384) | 75,264 | 677,376\n",
      "batch_normalization_371 | BatchNormalization | 0 | 0 | (14, 14, 384) | 75,264 | 0\n",
      "activation_362 | Activation | 0 | 0 | (14, 14, 384) | 75,264 | 0\n",
      "conv2d_316 | Conv2D | (1, 1, 384, 64) | 24,576 | (14, 14, 64) | 12,544 | 4,816,896\n",
      "batch_normalization_372 | BatchNormalization | 0 | 0 | (14, 14, 64) | 12,544 | 0\n",
      "add_50 | Add | 0 | 0 | (14, 14, 64) | 12,544 | 0\n",
      "conv2d_317 | Conv2D | (1, 1, 64, 384) | 24,576 | (14, 14, 384) | 75,264 | 4,816,896\n",
      "batch_normalization_373 | BatchNormalization | 0 | 0 | (14, 14, 384) | 75,264 | 0\n",
      "activation_363 | Activation | 0 | 0 | (14, 14, 384) | 75,264 | 0\n",
      "depthwise_conv2d_60 | DepthwiseConv2D | (3, 3, 384, 1) | 3,456 | (14, 14, 384) | 75,264 | 677,376\n",
      "batch_normalization_374 | BatchNormalization | 0 | 0 | (14, 14, 384) | 75,264 | 0\n",
      "activation_364 | Activation | 0 | 0 | (14, 14, 384) | 75,264 | 0\n",
      "conv2d_318 | Conv2D | (1, 1, 384, 64) | 24,576 | (14, 14, 64) | 12,544 | 4,816,896\n",
      "batch_normalization_375 | BatchNormalization | 0 | 0 | (14, 14, 64) | 12,544 | 0\n",
      "add_51 | Add | 0 | 0 | (14, 14, 64) | 12,544 | 0\n",
      "conv2d_319 | Conv2D | (1, 1, 64, 384) | 24,576 | (14, 14, 384) | 75,264 | 4,816,896\n",
      "batch_normalization_376 | BatchNormalization | 0 | 0 | (14, 14, 384) | 75,264 | 0\n",
      "activation_365 | Activation | 0 | 0 | (14, 14, 384) | 75,264 | 0\n",
      "depthwise_conv2d_61 | DepthwiseConv2D | (3, 3, 384, 1) | 3,456 | (14, 14, 384) | 75,264 | 677,376\n",
      "batch_normalization_377 | BatchNormalization | 0 | 0 | (14, 14, 384) | 75,264 | 0\n",
      "activation_366 | Activation | 0 | 0 | (14, 14, 384) | 75,264 | 0\n",
      "conv2d_320 | Conv2D | (1, 1, 384, 64) | 24,576 | (14, 14, 64) | 12,544 | 4,816,896\n",
      "batch_normalization_378 | BatchNormalization | 0 | 0 | (14, 14, 64) | 12,544 | 0\n",
      "add_52 | Add | 0 | 0 | (14, 14, 64) | 12,544 | 0\n",
      "conv2d_321 | Conv2D | (1, 1, 64, 384) | 24,576 | (14, 14, 384) | 75,264 | 4,816,896\n",
      "batch_normalization_379 | BatchNormalization | 0 | 0 | (14, 14, 384) | 75,264 | 0\n",
      "activation_367 | Activation | 0 | 0 | (14, 14, 384) | 75,264 | 0\n",
      "depthwise_conv2d_62 | DepthwiseConv2D | (3, 3, 384, 1) | 3,456 | (14, 14, 384) | 75,264 | 677,376\n",
      "batch_normalization_380 | BatchNormalization | 0 | 0 | (14, 14, 384) | 75,264 | 0\n",
      "activation_368 | Activation | 0 | 0 | (14, 14, 384) | 75,264 | 0\n",
      "conv2d_322 | Conv2D | (1, 1, 384, 96) | 36,864 | (14, 14, 96) | 18,816 | 7,225,344\n",
      "batch_normalization_381 | BatchNormalization | 0 | 0 | (14, 14, 96) | 18,816 | 0\n",
      "conv2d_323 | Conv2D | (1, 1, 96, 576) | 55,296 | (14, 14, 576) | 112,896 | 10,838,016\n",
      "batch_normalization_382 | BatchNormalization | 0 | 0 | (14, 14, 576) | 112,896 | 0\n",
      "activation_369 | Activation | 0 | 0 | (14, 14, 576) | 112,896 | 0\n",
      "depthwise_conv2d_63 | DepthwiseConv2D | (3, 3, 576, 1) | 5,184 | (14, 14, 576) | 112,896 | 1,016,064\n",
      "batch_normalization_383 | BatchNormalization | 0 | 0 | (14, 14, 576) | 112,896 | 0\n",
      "activation_370 | Activation | 0 | 0 | (14, 14, 576) | 112,896 | 0\n",
      "conv2d_324 | Conv2D | (1, 1, 576, 96) | 55,296 | (14, 14, 96) | 18,816 | 10,838,016\n",
      "batch_normalization_384 | BatchNormalization | 0 | 0 | (14, 14, 96) | 18,816 | 0\n",
      "add_53 | Add | 0 | 0 | (14, 14, 96) | 18,816 | 0\n",
      "conv2d_325 | Conv2D | (1, 1, 96, 576) | 55,296 | (14, 14, 576) | 112,896 | 10,838,016\n",
      "batch_normalization_385 | BatchNormalization | 0 | 0 | (14, 14, 576) | 112,896 | 0\n",
      "activation_371 | Activation | 0 | 0 | (14, 14, 576) | 112,896 | 0\n",
      "depthwise_conv2d_64 | DepthwiseConv2D | (3, 3, 576, 1) | 5,184 | (14, 14, 576) | 112,896 | 1,016,064\n",
      "batch_normalization_386 | BatchNormalization | 0 | 0 | (14, 14, 576) | 112,896 | 0\n",
      "activation_372 | Activation | 0 | 0 | (14, 14, 576) | 112,896 | 0\n",
      "conv2d_326 | Conv2D | (1, 1, 576, 96) | 55,296 | (14, 14, 96) | 18,816 | 10,838,016\n",
      "batch_normalization_387 | BatchNormalization | 0 | 0 | (14, 14, 96) | 18,816 | 0\n",
      "add_54 | Add | 0 | 0 | (14, 14, 96) | 18,816 | 0\n",
      "conv2d_327 | Conv2D | (1, 1, 96, 576) | 55,296 | (14, 14, 576) | 112,896 | 10,838,016\n",
      "batch_normalization_388 | BatchNormalization | 0 | 0 | (14, 14, 576) | 112,896 | 0\n",
      "activation_373 | Activation | 0 | 0 | (14, 14, 576) | 112,896 | 0\n",
      "depthwise_conv2d_65 | DepthwiseConv2D | (3, 3, 576, 1) | 5,184 | (7, 7, 576) | 28,224 | 254,016\n",
      "batch_normalization_389 | BatchNormalization | 0 | 0 | (7, 7, 576) | 28,224 | 0\n",
      "activation_374 | Activation | 0 | 0 | (7, 7, 576) | 28,224 | 0\n",
      "conv2d_328 | Conv2D | (1, 1, 576, 160) | 92,160 | (7, 7, 160) | 7,840 | 4,515,840\n",
      "batch_normalization_390 | BatchNormalization | 0 | 0 | (7, 7, 160) | 7,840 | 0\n",
      "conv2d_329 | Conv2D | (1, 1, 160, 960) | 153,600 | (7, 7, 960) | 47,040 | 7,526,400\n",
      "batch_normalization_391 | BatchNormalization | 0 | 0 | (7, 7, 960) | 47,040 | 0\n",
      "activation_375 | Activation | 0 | 0 | (7, 7, 960) | 47,040 | 0\n",
      "depthwise_conv2d_66 | DepthwiseConv2D | (3, 3, 960, 1) | 8,640 | (7, 7, 960) | 47,040 | 423,360\n",
      "batch_normalization_392 | BatchNormalization | 0 | 0 | (7, 7, 960) | 47,040 | 0\n",
      "activation_376 | Activation | 0 | 0 | (7, 7, 960) | 47,040 | 0\n",
      "conv2d_330 | Conv2D | (1, 1, 960, 160) | 153,600 | (7, 7, 160) | 7,840 | 7,526,400\n",
      "batch_normalization_393 | BatchNormalization | 0 | 0 | (7, 7, 160) | 7,840 | 0\n",
      "add_55 | Add | 0 | 0 | (7, 7, 160) | 7,840 | 0\n",
      "conv2d_331 | Conv2D | (1, 1, 160, 960) | 153,600 | (7, 7, 960) | 47,040 | 7,526,400\n",
      "batch_normalization_394 | BatchNormalization | 0 | 0 | (7, 7, 960) | 47,040 | 0\n",
      "activation_377 | Activation | 0 | 0 | (7, 7, 960) | 47,040 | 0\n",
      "depthwise_conv2d_67 | DepthwiseConv2D | (3, 3, 960, 1) | 8,640 | (7, 7, 960) | 47,040 | 423,360\n",
      "batch_normalization_395 | BatchNormalization | 0 | 0 | (7, 7, 960) | 47,040 | 0\n",
      "activation_378 | Activation | 0 | 0 | (7, 7, 960) | 47,040 | 0\n",
      "conv2d_332 | Conv2D | (1, 1, 960, 160) | 153,600 | (7, 7, 160) | 7,840 | 7,526,400\n",
      "batch_normalization_396 | BatchNormalization | 0 | 0 | (7, 7, 160) | 7,840 | 0\n",
      "add_56 | Add | 0 | 0 | (7, 7, 160) | 7,840 | 0\n",
      "conv2d_333 | Conv2D | (1, 1, 160, 960) | 153,600 | (7, 7, 960) | 47,040 | 7,526,400\n",
      "batch_normalization_397 | BatchNormalization | 0 | 0 | (7, 7, 960) | 47,040 | 0\n",
      "activation_379 | Activation | 0 | 0 | (7, 7, 960) | 47,040 | 0\n",
      "depthwise_conv2d_68 | DepthwiseConv2D | (3, 3, 960, 1) | 8,640 | (7, 7, 960) | 47,040 | 423,360\n",
      "batch_normalization_398 | BatchNormalization | 0 | 0 | (7, 7, 960) | 47,040 | 0\n",
      "activation_380 | Activation | 0 | 0 | (7, 7, 960) | 47,040 | 0\n",
      "conv2d_334 | Conv2D | (1, 1, 960, 320) | 307,200 | (7, 7, 320) | 15,680 | 15,052,800\n",
      "batch_normalization_399 | BatchNormalization | 0 | 0 | (7, 7, 320) | 15,680 | 0\n",
      "conv2d_335 | Conv2D | (1, 1, 320, 1280) | 409,600 | (7, 7, 1280) | 62,720 | 20,070,400\n",
      "batch_normalization_400 | BatchNormalization | 0 | 0 | (7, 7, 1280) | 62,720 | 0\n",
      "activation_381 | Activation | 0 | 0 | (7, 7, 1280) | 62,720 | 0\n",
      "global_average_pooling2d_6 | GlobalAveragePooling2D | 0 | 0 | (1280,) | 1,280 | 0\n",
      "reshape_7 | Reshape | 0 | 0 | (1, 1, 1280) | 1,280 | 0\n",
      "Dropout | Dropout | 0 | 0 | (1, 1, 1280) | 1,280 | 0\n",
      "conv2d_336 | Conv2D | (1, 1, 1280, 1000) | 1,280,000 | (1, 1, 1000) | 1,000 | 1,280,000\n",
      "softmax | Activation | 0 | 0 | (1, 1, 1000) | 1,000 | 0\n",
      "reshape_8 | Reshape | 0 | 0 | (1000,) | 1,000 | 0\n",
      "- | - | - | - | - | - | -\n",
      "- | - | - | Kernel Mem (Total) | - | Output Mem (Total) | FLOPS (Total)\n",
      "Summary | - | - | 3,470,784 | - | 21,039,992 | 313,619,328\n",
      "\n",
      "----------------------\n",
      "\n",
      "Model Name: model_4\n",
      "Overall FLOPS: 314 MFLOPS\n",
      "Overall Params: 23 MParams\n",
      "Operational Intensity = 3 FLOPS/Byte\n"
     ]
    }
   ],
   "source": [
    "intensity(MobileNetv2((224, 224, 3), 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer Name | Layer Type | Kernel Size | Kernel Mem | Output Size | Output Mem | FLOPS\n",
      "--- | --- | --- | --- | --- | --- | ---\n",
      "input_9 | InputLayer | 0 | 0 | (224, 224, 3) | 150,528 | 0\n",
      "block1_conv1 | Conv2D | (3, 3, 3, 64) | 1,728 | (224, 224, 64) | 3,211,264 | 86,704,128\n",
      "block1_conv2 | Conv2D | (3, 3, 64, 64) | 36,864 | (224, 224, 64) | 3,211,264 | 1,849,688,064\n",
      "block1_pool | MaxPooling2D | 0 | 0 | (112, 112, 64) | 802,816 | 0\n",
      "block2_conv1 | Conv2D | (3, 3, 64, 128) | 73,728 | (112, 112, 128) | 1,605,632 | 924,844,032\n",
      "block2_conv2 | Conv2D | (3, 3, 128, 128) | 147,456 | (112, 112, 128) | 1,605,632 | 1,849,688,064\n",
      "block2_pool | MaxPooling2D | 0 | 0 | (56, 56, 128) | 401,408 | 0\n",
      "block3_conv1 | Conv2D | (3, 3, 128, 256) | 294,912 | (56, 56, 256) | 802,816 | 924,844,032\n",
      "block3_conv2 | Conv2D | (3, 3, 256, 256) | 589,824 | (56, 56, 256) | 802,816 | 1,849,688,064\n",
      "block3_conv3 | Conv2D | (3, 3, 256, 256) | 589,824 | (56, 56, 256) | 802,816 | 1,849,688,064\n",
      "block3_pool | MaxPooling2D | 0 | 0 | (28, 28, 256) | 200,704 | 0\n",
      "block4_conv1 | Conv2D | (3, 3, 256, 512) | 1,179,648 | (28, 28, 512) | 401,408 | 924,844,032\n",
      "block4_conv2 | Conv2D | (3, 3, 512, 512) | 2,359,296 | (28, 28, 512) | 401,408 | 1,849,688,064\n",
      "block4_conv3 | Conv2D | (3, 3, 512, 512) | 2,359,296 | (28, 28, 512) | 401,408 | 1,849,688,064\n",
      "block4_pool | MaxPooling2D | 0 | 0 | (14, 14, 512) | 100,352 | 0\n",
      "block5_conv1 | Conv2D | (3, 3, 512, 512) | 2,359,296 | (14, 14, 512) | 100,352 | 462,422,016\n",
      "block5_conv2 | Conv2D | (3, 3, 512, 512) | 2,359,296 | (14, 14, 512) | 100,352 | 462,422,016\n",
      "block5_conv3 | Conv2D | (3, 3, 512, 512) | 2,359,296 | (14, 14, 512) | 100,352 | 462,422,016\n",
      "block5_pool | MaxPooling2D | 0 | 0 | (7, 7, 512) | 25,088 | 0\n",
      "flatten | Flatten | 0 | 0 | (25088,) | 25,088 | 0\n",
      "fc1 | Dense | (25088, 4096) | 102,760,448 | (4096,) | 4,096 | 102,760,448\n",
      "fc2 | Dense | (4096, 4096) | 16,777,216 | (4096,) | 4,096 | 16,777,216\n",
      "predictions | Dense | (4096, 1000) | 4,096,000 | (1000,) | 1,000 | 4,096,000\n",
      "- | - | - | - | - | - | -\n",
      "- | - | - | Kernel Mem (Total) | - | Output Mem (Total) | FLOPS (Total)\n",
      "Summary | - | - | 138,344,128 | - | 15,262,696 | 15,470,264,320\n",
      "\n",
      "----------------------\n",
      "\n",
      "Model Name: vgg16\n",
      "Overall FLOPS: 15470 MFLOPS\n",
      "Overall Params: 146 MParams\n",
      "Operational Intensity = 25 FLOPS/Byte\n"
     ]
    }
   ],
   "source": [
    "intensity(VGG16())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer Name | Layer Type | Kernel Size | Kernel Mem | Output Size | Output Mem | FLOPS\n",
      "--- | --- | --- | --- | --- | --- | ---\n",
      "input_8 | InputLayer | 0 | 0 | (224, 224, 3) | 150,528 | 0\n",
      "conv1 | Conv2D | (3, 3, 3, 32) | 864 | (112, 112, 32) | 401,408 | 10,838,016\n",
      "conv1_bn | BatchNormalization | 0 | 0 | (112, 112, 32) | 401,408 | 0\n",
      "conv1_relu | Activation | 0 | 0 | (112, 112, 32) | 401,408 | 0\n",
      "conv_dw_1 | DepthwiseConv2D | (3, 3, 32, 1) | 288 | (112, 112, 32) | 401,408 | 3,612,672\n",
      "conv_dw_1_bn | BatchNormalization | 0 | 0 | (112, 112, 32) | 401,408 | 0\n",
      "conv_dw_1_relu | Activation | 0 | 0 | (112, 112, 32) | 401,408 | 0\n",
      "conv_pw_1 | Conv2D | (1, 1, 32, 64) | 2,048 | (112, 112, 64) | 802,816 | 25,690,112\n",
      "conv_pw_1_bn | BatchNormalization | 0 | 0 | (112, 112, 64) | 802,816 | 0\n",
      "conv_pw_1_relu | Activation | 0 | 0 | (112, 112, 64) | 802,816 | 0\n",
      "conv_dw_2 | DepthwiseConv2D | (3, 3, 64, 1) | 576 | (56, 56, 64) | 200,704 | 1,806,336\n",
      "conv_dw_2_bn | BatchNormalization | 0 | 0 | (56, 56, 64) | 200,704 | 0\n",
      "conv_dw_2_relu | Activation | 0 | 0 | (56, 56, 64) | 200,704 | 0\n",
      "conv_pw_2 | Conv2D | (1, 1, 64, 128) | 8,192 | (56, 56, 128) | 401,408 | 25,690,112\n",
      "conv_pw_2_bn | BatchNormalization | 0 | 0 | (56, 56, 128) | 401,408 | 0\n",
      "conv_pw_2_relu | Activation | 0 | 0 | (56, 56, 128) | 401,408 | 0\n",
      "conv_dw_3 | DepthwiseConv2D | (3, 3, 128, 1) | 1,152 | (56, 56, 128) | 401,408 | 3,612,672\n",
      "conv_dw_3_bn | BatchNormalization | 0 | 0 | (56, 56, 128) | 401,408 | 0\n",
      "conv_dw_3_relu | Activation | 0 | 0 | (56, 56, 128) | 401,408 | 0\n",
      "conv_pw_3 | Conv2D | (1, 1, 128, 128) | 16,384 | (56, 56, 128) | 401,408 | 51,380,224\n",
      "conv_pw_3_bn | BatchNormalization | 0 | 0 | (56, 56, 128) | 401,408 | 0\n",
      "conv_pw_3_relu | Activation | 0 | 0 | (56, 56, 128) | 401,408 | 0\n",
      "conv_dw_4 | DepthwiseConv2D | (3, 3, 128, 1) | 1,152 | (28, 28, 128) | 100,352 | 903,168\n",
      "conv_dw_4_bn | BatchNormalization | 0 | 0 | (28, 28, 128) | 100,352 | 0\n",
      "conv_dw_4_relu | Activation | 0 | 0 | (28, 28, 128) | 100,352 | 0\n",
      "conv_pw_4 | Conv2D | (1, 1, 128, 256) | 32,768 | (28, 28, 256) | 200,704 | 25,690,112\n",
      "conv_pw_4_bn | BatchNormalization | 0 | 0 | (28, 28, 256) | 200,704 | 0\n",
      "conv_pw_4_relu | Activation | 0 | 0 | (28, 28, 256) | 200,704 | 0\n",
      "conv_dw_5 | DepthwiseConv2D | (3, 3, 256, 1) | 2,304 | (28, 28, 256) | 200,704 | 1,806,336\n",
      "conv_dw_5_bn | BatchNormalization | 0 | 0 | (28, 28, 256) | 200,704 | 0\n",
      "conv_dw_5_relu | Activation | 0 | 0 | (28, 28, 256) | 200,704 | 0\n",
      "conv_pw_5 | Conv2D | (1, 1, 256, 256) | 65,536 | (28, 28, 256) | 200,704 | 51,380,224\n",
      "conv_pw_5_bn | BatchNormalization | 0 | 0 | (28, 28, 256) | 200,704 | 0\n",
      "conv_pw_5_relu | Activation | 0 | 0 | (28, 28, 256) | 200,704 | 0\n",
      "conv_dw_6 | DepthwiseConv2D | (3, 3, 256, 1) | 2,304 | (14, 14, 256) | 50,176 | 451,584\n",
      "conv_dw_6_bn | BatchNormalization | 0 | 0 | (14, 14, 256) | 50,176 | 0\n",
      "conv_dw_6_relu | Activation | 0 | 0 | (14, 14, 256) | 50,176 | 0\n",
      "conv_pw_6 | Conv2D | (1, 1, 256, 512) | 131,072 | (14, 14, 512) | 100,352 | 25,690,112\n",
      "conv_pw_6_bn | BatchNormalization | 0 | 0 | (14, 14, 512) | 100,352 | 0\n",
      "conv_pw_6_relu | Activation | 0 | 0 | (14, 14, 512) | 100,352 | 0\n",
      "conv_dw_7 | DepthwiseConv2D | (3, 3, 512, 1) | 4,608 | (14, 14, 512) | 100,352 | 903,168\n",
      "conv_dw_7_bn | BatchNormalization | 0 | 0 | (14, 14, 512) | 100,352 | 0\n",
      "conv_dw_7_relu | Activation | 0 | 0 | (14, 14, 512) | 100,352 | 0\n",
      "conv_pw_7 | Conv2D | (1, 1, 512, 512) | 262,144 | (14, 14, 512) | 100,352 | 51,380,224\n",
      "conv_pw_7_bn | BatchNormalization | 0 | 0 | (14, 14, 512) | 100,352 | 0\n",
      "conv_pw_7_relu | Activation | 0 | 0 | (14, 14, 512) | 100,352 | 0\n",
      "conv_dw_8 | DepthwiseConv2D | (3, 3, 512, 1) | 4,608 | (14, 14, 512) | 100,352 | 903,168\n",
      "conv_dw_8_bn | BatchNormalization | 0 | 0 | (14, 14, 512) | 100,352 | 0\n",
      "conv_dw_8_relu | Activation | 0 | 0 | (14, 14, 512) | 100,352 | 0\n",
      "conv_pw_8 | Conv2D | (1, 1, 512, 512) | 262,144 | (14, 14, 512) | 100,352 | 51,380,224\n",
      "conv_pw_8_bn | BatchNormalization | 0 | 0 | (14, 14, 512) | 100,352 | 0\n",
      "conv_pw_8_relu | Activation | 0 | 0 | (14, 14, 512) | 100,352 | 0\n",
      "conv_dw_9 | DepthwiseConv2D | (3, 3, 512, 1) | 4,608 | (14, 14, 512) | 100,352 | 903,168\n",
      "conv_dw_9_bn | BatchNormalization | 0 | 0 | (14, 14, 512) | 100,352 | 0\n",
      "conv_dw_9_relu | Activation | 0 | 0 | (14, 14, 512) | 100,352 | 0\n",
      "conv_pw_9 | Conv2D | (1, 1, 512, 512) | 262,144 | (14, 14, 512) | 100,352 | 51,380,224\n",
      "conv_pw_9_bn | BatchNormalization | 0 | 0 | (14, 14, 512) | 100,352 | 0\n",
      "conv_pw_9_relu | Activation | 0 | 0 | (14, 14, 512) | 100,352 | 0\n",
      "conv_dw_10 | DepthwiseConv2D | (3, 3, 512, 1) | 4,608 | (14, 14, 512) | 100,352 | 903,168\n",
      "conv_dw_10_bn | BatchNormalization | 0 | 0 | (14, 14, 512) | 100,352 | 0\n",
      "conv_dw_10_relu | Activation | 0 | 0 | (14, 14, 512) | 100,352 | 0\n",
      "conv_pw_10 | Conv2D | (1, 1, 512, 512) | 262,144 | (14, 14, 512) | 100,352 | 51,380,224\n",
      "conv_pw_10_bn | BatchNormalization | 0 | 0 | (14, 14, 512) | 100,352 | 0\n",
      "conv_pw_10_relu | Activation | 0 | 0 | (14, 14, 512) | 100,352 | 0\n",
      "conv_dw_11 | DepthwiseConv2D | (3, 3, 512, 1) | 4,608 | (14, 14, 512) | 100,352 | 903,168\n",
      "conv_dw_11_bn | BatchNormalization | 0 | 0 | (14, 14, 512) | 100,352 | 0\n",
      "conv_dw_11_relu | Activation | 0 | 0 | (14, 14, 512) | 100,352 | 0\n",
      "conv_pw_11 | Conv2D | (1, 1, 512, 512) | 262,144 | (14, 14, 512) | 100,352 | 51,380,224\n",
      "conv_pw_11_bn | BatchNormalization | 0 | 0 | (14, 14, 512) | 100,352 | 0\n",
      "conv_pw_11_relu | Activation | 0 | 0 | (14, 14, 512) | 100,352 | 0\n",
      "conv_dw_12 | DepthwiseConv2D | (3, 3, 512, 1) | 4,608 | (7, 7, 512) | 25,088 | 225,792\n",
      "conv_dw_12_bn | BatchNormalization | 0 | 0 | (7, 7, 512) | 25,088 | 0\n",
      "conv_dw_12_relu | Activation | 0 | 0 | (7, 7, 512) | 25,088 | 0\n",
      "conv_pw_12 | Conv2D | (1, 1, 512, 1024) | 524,288 | (7, 7, 1024) | 50,176 | 25,690,112\n",
      "conv_pw_12_bn | BatchNormalization | 0 | 0 | (7, 7, 1024) | 50,176 | 0\n",
      "conv_pw_12_relu | Activation | 0 | 0 | (7, 7, 1024) | 50,176 | 0\n",
      "conv_dw_13 | DepthwiseConv2D | (3, 3, 1024, 1) | 9,216 | (7, 7, 1024) | 50,176 | 451,584\n",
      "conv_dw_13_bn | BatchNormalization | 0 | 0 | (7, 7, 1024) | 50,176 | 0\n",
      "conv_dw_13_relu | Activation | 0 | 0 | (7, 7, 1024) | 50,176 | 0\n",
      "conv_pw_13 | Conv2D | (1, 1, 1024, 1024) | 1,048,576 | (7, 7, 1024) | 50,176 | 51,380,224\n",
      "conv_pw_13_bn | BatchNormalization | 0 | 0 | (7, 7, 1024) | 50,176 | 0\n",
      "conv_pw_13_relu | Activation | 0 | 0 | (7, 7, 1024) | 50,176 | 0\n",
      "global_average_pooling2d_5 | GlobalAveragePooling2D | 0 | 0 | (1024,) | 1,024 | 0\n",
      "reshape_1 | Reshape | 0 | 0 | (1, 1, 1024) | 1,024 | 0\n",
      "dropout | Dropout | 0 | 0 | (1, 1, 1024) | 1,024 | 0\n",
      "conv_preds | Conv2D | (1, 1, 1024, 1000) | 1,024,000 | (1, 1, 1000) | 1,000 | 1,024,000\n",
      "act_softmax | Activation | 0 | 0 | (1, 1, 1000) | 1,000 | 0\n",
      "reshape_2 | Reshape | 0 | 0 | (1000,) | 1,000 | 0\n",
      "- | - | - | - | - | - | -\n",
      "- | - | - | Kernel Mem (Total) | - | Output Mem (Total) | FLOPS (Total)\n",
      "Summary | - | - | 4,209,088 | - | 15,284,664 | 568,740,352\n",
      "\n",
      "----------------------\n",
      "\n",
      "Model Name: mobilenet_1.00_224\n",
      "Overall FLOPS: 569 MFLOPS\n",
      "Overall Params: 19 MParams\n",
      "Operational Intensity = 7 FLOPS/Byte\n"
     ]
    }
   ],
   "source": [
    "intensity(MobileNet())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer Name | Layer Type | Kernel Size | Kernel Mem | Output Size | Output Mem | FLOPS\n",
      "--- | --- | --- | --- | --- | --- | ---\n",
      "input_4 | InputLayer | 0 | 0 | (299, 299, 3) | 268,203 | 0\n",
      "block1_conv1 | Conv2D | (3, 3, 3, 32) | 864 | (149, 149, 32) | 710,432 | 19,181,664\n",
      "block1_conv1_bn | BatchNormalization | 0 | 0 | (149, 149, 32) | 710,432 | 0\n",
      "block1_conv1_act | Activation | 0 | 0 | (149, 149, 32) | 710,432 | 0\n",
      "block1_conv2 | Conv2D | (3, 3, 32, 64) | 18,432 | (147, 147, 64) | 1,382,976 | 398,297,088\n",
      "block1_conv2_bn | BatchNormalization | 0 | 0 | (147, 147, 64) | 1,382,976 | 0\n",
      "block1_conv2_act | Activation | 0 | 0 | (147, 147, 64) | 1,382,976 | 0\n",
      "block2_sepconv1 | SeparableConv2D | (3, 3, 64, 1) | 576 | (147, 147, 128) | 2,765,952 | 201,914,496\n",
      "block2_sepconv1_bn | BatchNormalization | 0 | 0 | (147, 147, 128) | 2,765,952 | 0\n",
      "block2_sepconv2_act | Activation | 0 | 0 | (147, 147, 128) | 2,765,952 | 0\n",
      "block2_sepconv2 | SeparableConv2D | (3, 3, 128, 1) | 1,152 | (147, 147, 128) | 2,765,952 | 378,935,424\n",
      "block2_sepconv2_bn | BatchNormalization | 0 | 0 | (147, 147, 128) | 2,765,952 | 0\n",
      "conv2d_5 | Conv2D | (1, 1, 64, 128) | 8,192 | (74, 74, 128) | 700,928 | 44,859,392\n",
      "block2_pool | MaxPooling2D | 0 | 0 | (74, 74, 128) | 700,928 | 0\n",
      "batch_normalization_5 | BatchNormalization | 0 | 0 | (74, 74, 128) | 700,928 | 0\n",
      "add_13 | Add | 0 | 0 | (74, 74, 128) | 700,928 | 0\n",
      "block3_sepconv1_act | Activation | 0 | 0 | (74, 74, 128) | 700,928 | 0\n",
      "block3_sepconv1 | SeparableConv2D | (3, 3, 128, 1) | 1,152 | (74, 74, 256) | 1,401,856 | 192,054,272\n",
      "block3_sepconv1_bn | BatchNormalization | 0 | 0 | (74, 74, 256) | 1,401,856 | 0\n",
      "block3_sepconv2_act | Activation | 0 | 0 | (74, 74, 256) | 1,401,856 | 0\n",
      "block3_sepconv2 | SeparableConv2D | (3, 3, 256, 1) | 2,304 | (74, 74, 256) | 1,401,856 | 371,491,840\n",
      "block3_sepconv2_bn | BatchNormalization | 0 | 0 | (74, 74, 256) | 1,401,856 | 0\n",
      "conv2d_6 | Conv2D | (1, 1, 128, 256) | 32,768 | (37, 37, 256) | 350,464 | 44,859,392\n",
      "block3_pool | MaxPooling2D | 0 | 0 | (37, 37, 256) | 350,464 | 0\n",
      "batch_normalization_6 | BatchNormalization | 0 | 0 | (37, 37, 256) | 350,464 | 0\n",
      "add_14 | Add | 0 | 0 | (37, 37, 256) | 350,464 | 0\n",
      "block4_sepconv1_act | Activation | 0 | 0 | (37, 37, 256) | 350,464 | 0\n",
      "block4_sepconv1 | SeparableConv2D | (3, 3, 256, 1) | 2,304 | (37, 37, 728) | 996,632 | 264,107,480\n",
      "block4_sepconv1_bn | BatchNormalization | 0 | 0 | (37, 37, 728) | 996,632 | 0\n",
      "block4_sepconv2_act | Activation | 0 | 0 | (37, 37, 728) | 996,632 | 0\n",
      "block4_sepconv2 | SeparableConv2D | (3, 3, 728, 1) | 6,552 | (37, 37, 728) | 996,632 | 734,517,784\n",
      "block4_sepconv2_bn | BatchNormalization | 0 | 0 | (37, 37, 728) | 996,632 | 0\n",
      "conv2d_7 | Conv2D | (1, 1, 256, 728) | 186,368 | (19, 19, 728) | 262,808 | 67,278,848\n",
      "block4_pool | MaxPooling2D | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "batch_normalization_7 | BatchNormalization | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "add_15 | Add | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block5_sepconv1_act | Activation | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block5_sepconv1 | SeparableConv2D | (3, 3, 728, 1) | 6,552 | (19, 19, 728) | 262,808 | 193,689,496\n",
      "block5_sepconv1_bn | BatchNormalization | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block5_sepconv2_act | Activation | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block5_sepconv2 | SeparableConv2D | (3, 3, 728, 1) | 6,552 | (19, 19, 728) | 262,808 | 193,689,496\n",
      "block5_sepconv2_bn | BatchNormalization | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block5_sepconv3_act | Activation | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block5_sepconv3 | SeparableConv2D | (3, 3, 728, 1) | 6,552 | (19, 19, 728) | 262,808 | 193,689,496\n",
      "block5_sepconv3_bn | BatchNormalization | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "add_16 | Add | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block6_sepconv1_act | Activation | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block6_sepconv1 | SeparableConv2D | (3, 3, 728, 1) | 6,552 | (19, 19, 728) | 262,808 | 193,689,496\n",
      "block6_sepconv1_bn | BatchNormalization | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block6_sepconv2_act | Activation | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block6_sepconv2 | SeparableConv2D | (3, 3, 728, 1) | 6,552 | (19, 19, 728) | 262,808 | 193,689,496\n",
      "block6_sepconv2_bn | BatchNormalization | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block6_sepconv3_act | Activation | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block6_sepconv3 | SeparableConv2D | (3, 3, 728, 1) | 6,552 | (19, 19, 728) | 262,808 | 193,689,496\n",
      "block6_sepconv3_bn | BatchNormalization | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "add_17 | Add | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block7_sepconv1_act | Activation | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block7_sepconv1 | SeparableConv2D | (3, 3, 728, 1) | 6,552 | (19, 19, 728) | 262,808 | 193,689,496\n",
      "block7_sepconv1_bn | BatchNormalization | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block7_sepconv2_act | Activation | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block7_sepconv2 | SeparableConv2D | (3, 3, 728, 1) | 6,552 | (19, 19, 728) | 262,808 | 193,689,496\n",
      "block7_sepconv2_bn | BatchNormalization | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block7_sepconv3_act | Activation | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block7_sepconv3 | SeparableConv2D | (3, 3, 728, 1) | 6,552 | (19, 19, 728) | 262,808 | 193,689,496\n",
      "block7_sepconv3_bn | BatchNormalization | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "add_18 | Add | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block8_sepconv1_act | Activation | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block8_sepconv1 | SeparableConv2D | (3, 3, 728, 1) | 6,552 | (19, 19, 728) | 262,808 | 193,689,496\n",
      "block8_sepconv1_bn | BatchNormalization | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block8_sepconv2_act | Activation | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block8_sepconv2 | SeparableConv2D | (3, 3, 728, 1) | 6,552 | (19, 19, 728) | 262,808 | 193,689,496\n",
      "block8_sepconv2_bn | BatchNormalization | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block8_sepconv3_act | Activation | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block8_sepconv3 | SeparableConv2D | (3, 3, 728, 1) | 6,552 | (19, 19, 728) | 262,808 | 193,689,496\n",
      "block8_sepconv3_bn | BatchNormalization | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "add_19 | Add | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block9_sepconv1_act | Activation | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block9_sepconv1 | SeparableConv2D | (3, 3, 728, 1) | 6,552 | (19, 19, 728) | 262,808 | 193,689,496\n",
      "block9_sepconv1_bn | BatchNormalization | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block9_sepconv2_act | Activation | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block9_sepconv2 | SeparableConv2D | (3, 3, 728, 1) | 6,552 | (19, 19, 728) | 262,808 | 193,689,496\n",
      "block9_sepconv2_bn | BatchNormalization | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block9_sepconv3_act | Activation | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block9_sepconv3 | SeparableConv2D | (3, 3, 728, 1) | 6,552 | (19, 19, 728) | 262,808 | 193,689,496\n",
      "block9_sepconv3_bn | BatchNormalization | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "add_20 | Add | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block10_sepconv1_act | Activation | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block10_sepconv1 | SeparableConv2D | (3, 3, 728, 1) | 6,552 | (19, 19, 728) | 262,808 | 193,689,496\n",
      "block10_sepconv1_bn | BatchNormalization | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block10_sepconv2_act | Activation | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block10_sepconv2 | SeparableConv2D | (3, 3, 728, 1) | 6,552 | (19, 19, 728) | 262,808 | 193,689,496\n",
      "block10_sepconv2_bn | BatchNormalization | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block10_sepconv3_act | Activation | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block10_sepconv3 | SeparableConv2D | (3, 3, 728, 1) | 6,552 | (19, 19, 728) | 262,808 | 193,689,496\n",
      "block10_sepconv3_bn | BatchNormalization | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "add_21 | Add | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block11_sepconv1_act | Activation | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block11_sepconv1 | SeparableConv2D | (3, 3, 728, 1) | 6,552 | (19, 19, 728) | 262,808 | 193,689,496\n",
      "block11_sepconv1_bn | BatchNormalization | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block11_sepconv2_act | Activation | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block11_sepconv2 | SeparableConv2D | (3, 3, 728, 1) | 6,552 | (19, 19, 728) | 262,808 | 193,689,496\n",
      "block11_sepconv2_bn | BatchNormalization | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block11_sepconv3_act | Activation | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block11_sepconv3 | SeparableConv2D | (3, 3, 728, 1) | 6,552 | (19, 19, 728) | 262,808 | 193,689,496\n",
      "block11_sepconv3_bn | BatchNormalization | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "add_22 | Add | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block12_sepconv1_act | Activation | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block12_sepconv1 | SeparableConv2D | (3, 3, 728, 1) | 6,552 | (19, 19, 728) | 262,808 | 193,689,496\n",
      "block12_sepconv1_bn | BatchNormalization | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block12_sepconv2_act | Activation | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block12_sepconv2 | SeparableConv2D | (3, 3, 728, 1) | 6,552 | (19, 19, 728) | 262,808 | 193,689,496\n",
      "block12_sepconv2_bn | BatchNormalization | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block12_sepconv3_act | Activation | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block12_sepconv3 | SeparableConv2D | (3, 3, 728, 1) | 6,552 | (19, 19, 728) | 262,808 | 193,689,496\n",
      "block12_sepconv3_bn | BatchNormalization | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "add_23 | Add | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block13_sepconv1_act | Activation | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block13_sepconv1 | SeparableConv2D | (3, 3, 728, 1) | 6,552 | (19, 19, 728) | 262,808 | 193,689,496\n",
      "block13_sepconv1_bn | BatchNormalization | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block13_sepconv2_act | Activation | 0 | 0 | (19, 19, 728) | 262,808 | 0\n",
      "block13_sepconv2 | SeparableConv2D | (3, 3, 728, 1) | 6,552 | (19, 19, 1024) | 369,664 | 272,442,368\n",
      "block13_sepconv2_bn | BatchNormalization | 0 | 0 | (19, 19, 1024) | 369,664 | 0\n",
      "conv2d_8 | Conv2D | (1, 1, 728, 1024) | 745,472 | (10, 10, 1024) | 102,400 | 74,547,200\n",
      "block13_pool | MaxPooling2D | 0 | 0 | (10, 10, 1024) | 102,400 | 0\n",
      "batch_normalization_8 | BatchNormalization | 0 | 0 | (10, 10, 1024) | 102,400 | 0\n",
      "add_24 | Add | 0 | 0 | (10, 10, 1024) | 102,400 | 0\n",
      "block14_sepconv1 | SeparableConv2D | (3, 3, 1024, 1) | 9,216 | (10, 10, 1536) | 153,600 | 158,668,800\n",
      "block14_sepconv1_bn | BatchNormalization | 0 | 0 | (10, 10, 1536) | 153,600 | 0\n",
      "block14_sepconv1_act | Activation | 0 | 0 | (10, 10, 1536) | 153,600 | 0\n",
      "block14_sepconv2 | SeparableConv2D | (3, 3, 1536, 1) | 13,824 | (10, 10, 2048) | 204,800 | 316,416,000\n",
      "block14_sepconv2_bn | BatchNormalization | 0 | 0 | (10, 10, 2048) | 204,800 | 0\n",
      "block14_sepconv2_act | Activation | 0 | 0 | (10, 10, 2048) | 204,800 | 0\n",
      "avg_pool | GlobalAveragePooling2D | 0 | 0 | (2048,) | 2,048 | 0\n",
      "predictions | Dense | (2048, 1000) | 2,048,000 | (1000,) | 1,000 | 2,048,000\n",
      "- | - | - | - | - | - | -\n",
      "- | - | - | Kernel Mem (Total) | - | Output Mem (Total) | FLOPS (Total)\n",
      "Summary | - | - | 3,247,528 | - | 62,981,867 | 8,383,857,448\n",
      "\n",
      "----------------------\n",
      "\n",
      "Model Name: xception\n",
      "Overall FLOPS: 7995 MFLOPS\n",
      "Overall Memory: 63 MB\n",
      "Operational Intensity = 32 FLOPS/Byte\n"
     ]
    }
   ],
   "source": [
    "intensity(Xception(input_shape=(299, 299, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer Name | Layer Type | Kernel Size | Kernel Mem | Output Size | Output Mem | FLOPS\n",
      "--- | --- | --- | --- | --- | --- | ---\n",
      "input_7 | InputLayer | 0 | 0 | (224, 224, 3) | 150,528 | 0\n",
      "conv1 | Conv2D | (7, 7, 3, 64) | 9,408 | (112, 112, 64) | 802,816 | 118,013,952\n",
      "bn_conv1 | BatchNormalization | 0 | 0 | (112, 112, 64) | 802,816 | 0\n",
      "activation_297 | Activation | 0 | 0 | (112, 112, 64) | 802,816 | 0\n",
      "max_pooling2d_9 | MaxPooling2D | 0 | 0 | (55, 55, 64) | 193,600 | 0\n",
      "res2a_branch2a | Conv2D | (1, 1, 64, 64) | 4,096 | (55, 55, 64) | 193,600 | 12,390,400\n",
      "bn2a_branch2a | BatchNormalization | 0 | 0 | (55, 55, 64) | 193,600 | 0\n",
      "activation_298 | Activation | 0 | 0 | (55, 55, 64) | 193,600 | 0\n",
      "res2a_branch2b | Conv2D | (3, 3, 64, 64) | 36,864 | (55, 55, 64) | 193,600 | 111,513,600\n",
      "bn2a_branch2b | BatchNormalization | 0 | 0 | (55, 55, 64) | 193,600 | 0\n",
      "activation_299 | Activation | 0 | 0 | (55, 55, 64) | 193,600 | 0\n",
      "res2a_branch2c | Conv2D | (1, 1, 64, 256) | 16,384 | (55, 55, 256) | 774,400 | 49,561,600\n",
      "res2a_branch1 | Conv2D | (1, 1, 64, 256) | 16,384 | (55, 55, 256) | 774,400 | 49,561,600\n",
      "bn2a_branch2c | BatchNormalization | 0 | 0 | (55, 55, 256) | 774,400 | 0\n",
      "bn2a_branch1 | BatchNormalization | 0 | 0 | (55, 55, 256) | 774,400 | 0\n",
      "add_31 | Add | 0 | 0 | (55, 55, 256) | 774,400 | 0\n",
      "activation_300 | Activation | 0 | 0 | (55, 55, 256) | 774,400 | 0\n",
      "res2b_branch2a | Conv2D | (1, 1, 256, 64) | 16,384 | (55, 55, 64) | 193,600 | 49,561,600\n",
      "bn2b_branch2a | BatchNormalization | 0 | 0 | (55, 55, 64) | 193,600 | 0\n",
      "activation_301 | Activation | 0 | 0 | (55, 55, 64) | 193,600 | 0\n",
      "res2b_branch2b | Conv2D | (3, 3, 64, 64) | 36,864 | (55, 55, 64) | 193,600 | 111,513,600\n",
      "bn2b_branch2b | BatchNormalization | 0 | 0 | (55, 55, 64) | 193,600 | 0\n",
      "activation_302 | Activation | 0 | 0 | (55, 55, 64) | 193,600 | 0\n",
      "res2b_branch2c | Conv2D | (1, 1, 64, 256) | 16,384 | (55, 55, 256) | 774,400 | 49,561,600\n",
      "bn2b_branch2c | BatchNormalization | 0 | 0 | (55, 55, 256) | 774,400 | 0\n",
      "add_32 | Add | 0 | 0 | (55, 55, 256) | 774,400 | 0\n",
      "activation_303 | Activation | 0 | 0 | (55, 55, 256) | 774,400 | 0\n",
      "res2c_branch2a | Conv2D | (1, 1, 256, 64) | 16,384 | (55, 55, 64) | 193,600 | 49,561,600\n",
      "bn2c_branch2a | BatchNormalization | 0 | 0 | (55, 55, 64) | 193,600 | 0\n",
      "activation_304 | Activation | 0 | 0 | (55, 55, 64) | 193,600 | 0\n",
      "res2c_branch2b | Conv2D | (3, 3, 64, 64) | 36,864 | (55, 55, 64) | 193,600 | 111,513,600\n",
      "bn2c_branch2b | BatchNormalization | 0 | 0 | (55, 55, 64) | 193,600 | 0\n",
      "activation_305 | Activation | 0 | 0 | (55, 55, 64) | 193,600 | 0\n",
      "res2c_branch2c | Conv2D | (1, 1, 64, 256) | 16,384 | (55, 55, 256) | 774,400 | 49,561,600\n",
      "bn2c_branch2c | BatchNormalization | 0 | 0 | (55, 55, 256) | 774,400 | 0\n",
      "add_33 | Add | 0 | 0 | (55, 55, 256) | 774,400 | 0\n",
      "activation_306 | Activation | 0 | 0 | (55, 55, 256) | 774,400 | 0\n",
      "res3a_branch2a | Conv2D | (1, 1, 256, 128) | 32,768 | (28, 28, 128) | 100,352 | 25,690,112\n",
      "bn3a_branch2a | BatchNormalization | 0 | 0 | (28, 28, 128) | 100,352 | 0\n",
      "activation_307 | Activation | 0 | 0 | (28, 28, 128) | 100,352 | 0\n",
      "res3a_branch2b | Conv2D | (3, 3, 128, 128) | 147,456 | (28, 28, 128) | 100,352 | 115,605,504\n",
      "bn3a_branch2b | BatchNormalization | 0 | 0 | (28, 28, 128) | 100,352 | 0\n",
      "activation_308 | Activation | 0 | 0 | (28, 28, 128) | 100,352 | 0\n",
      "res3a_branch2c | Conv2D | (1, 1, 128, 512) | 65,536 | (28, 28, 512) | 401,408 | 51,380,224\n",
      "res3a_branch1 | Conv2D | (1, 1, 256, 512) | 131,072 | (28, 28, 512) | 401,408 | 102,760,448\n",
      "bn3a_branch2c | BatchNormalization | 0 | 0 | (28, 28, 512) | 401,408 | 0\n",
      "bn3a_branch1 | BatchNormalization | 0 | 0 | (28, 28, 512) | 401,408 | 0\n",
      "add_34 | Add | 0 | 0 | (28, 28, 512) | 401,408 | 0\n",
      "activation_309 | Activation | 0 | 0 | (28, 28, 512) | 401,408 | 0\n",
      "res3b_branch2a | Conv2D | (1, 1, 512, 128) | 65,536 | (28, 28, 128) | 100,352 | 51,380,224\n",
      "bn3b_branch2a | BatchNormalization | 0 | 0 | (28, 28, 128) | 100,352 | 0\n",
      "activation_310 | Activation | 0 | 0 | (28, 28, 128) | 100,352 | 0\n",
      "res3b_branch2b | Conv2D | (3, 3, 128, 128) | 147,456 | (28, 28, 128) | 100,352 | 115,605,504\n",
      "bn3b_branch2b | BatchNormalization | 0 | 0 | (28, 28, 128) | 100,352 | 0\n",
      "activation_311 | Activation | 0 | 0 | (28, 28, 128) | 100,352 | 0\n",
      "res3b_branch2c | Conv2D | (1, 1, 128, 512) | 65,536 | (28, 28, 512) | 401,408 | 51,380,224\n",
      "bn3b_branch2c | BatchNormalization | 0 | 0 | (28, 28, 512) | 401,408 | 0\n",
      "add_35 | Add | 0 | 0 | (28, 28, 512) | 401,408 | 0\n",
      "activation_312 | Activation | 0 | 0 | (28, 28, 512) | 401,408 | 0\n",
      "res3c_branch2a | Conv2D | (1, 1, 512, 128) | 65,536 | (28, 28, 128) | 100,352 | 51,380,224\n",
      "bn3c_branch2a | BatchNormalization | 0 | 0 | (28, 28, 128) | 100,352 | 0\n",
      "activation_313 | Activation | 0 | 0 | (28, 28, 128) | 100,352 | 0\n",
      "res3c_branch2b | Conv2D | (3, 3, 128, 128) | 147,456 | (28, 28, 128) | 100,352 | 115,605,504\n",
      "bn3c_branch2b | BatchNormalization | 0 | 0 | (28, 28, 128) | 100,352 | 0\n",
      "activation_314 | Activation | 0 | 0 | (28, 28, 128) | 100,352 | 0\n",
      "res3c_branch2c | Conv2D | (1, 1, 128, 512) | 65,536 | (28, 28, 512) | 401,408 | 51,380,224\n",
      "bn3c_branch2c | BatchNormalization | 0 | 0 | (28, 28, 512) | 401,408 | 0\n",
      "add_36 | Add | 0 | 0 | (28, 28, 512) | 401,408 | 0\n",
      "activation_315 | Activation | 0 | 0 | (28, 28, 512) | 401,408 | 0\n",
      "res3d_branch2a | Conv2D | (1, 1, 512, 128) | 65,536 | (28, 28, 128) | 100,352 | 51,380,224\n",
      "bn3d_branch2a | BatchNormalization | 0 | 0 | (28, 28, 128) | 100,352 | 0\n",
      "activation_316 | Activation | 0 | 0 | (28, 28, 128) | 100,352 | 0\n",
      "res3d_branch2b | Conv2D | (3, 3, 128, 128) | 147,456 | (28, 28, 128) | 100,352 | 115,605,504\n",
      "bn3d_branch2b | BatchNormalization | 0 | 0 | (28, 28, 128) | 100,352 | 0\n",
      "activation_317 | Activation | 0 | 0 | (28, 28, 128) | 100,352 | 0\n",
      "res3d_branch2c | Conv2D | (1, 1, 128, 512) | 65,536 | (28, 28, 512) | 401,408 | 51,380,224\n",
      "bn3d_branch2c | BatchNormalization | 0 | 0 | (28, 28, 512) | 401,408 | 0\n",
      "add_37 | Add | 0 | 0 | (28, 28, 512) | 401,408 | 0\n",
      "activation_318 | Activation | 0 | 0 | (28, 28, 512) | 401,408 | 0\n",
      "res4a_branch2a | Conv2D | (1, 1, 512, 256) | 131,072 | (14, 14, 256) | 50,176 | 25,690,112\n",
      "bn4a_branch2a | BatchNormalization | 0 | 0 | (14, 14, 256) | 50,176 | 0\n",
      "activation_319 | Activation | 0 | 0 | (14, 14, 256) | 50,176 | 0\n",
      "res4a_branch2b | Conv2D | (3, 3, 256, 256) | 589,824 | (14, 14, 256) | 50,176 | 115,605,504\n",
      "bn4a_branch2b | BatchNormalization | 0 | 0 | (14, 14, 256) | 50,176 | 0\n",
      "activation_320 | Activation | 0 | 0 | (14, 14, 256) | 50,176 | 0\n",
      "res4a_branch2c | Conv2D | (1, 1, 256, 1024) | 262,144 | (14, 14, 1024) | 200,704 | 51,380,224\n",
      "res4a_branch1 | Conv2D | (1, 1, 512, 1024) | 524,288 | (14, 14, 1024) | 200,704 | 102,760,448\n",
      "bn4a_branch2c | BatchNormalization | 0 | 0 | (14, 14, 1024) | 200,704 | 0\n",
      "bn4a_branch1 | BatchNormalization | 0 | 0 | (14, 14, 1024) | 200,704 | 0\n",
      "add_38 | Add | 0 | 0 | (14, 14, 1024) | 200,704 | 0\n",
      "activation_321 | Activation | 0 | 0 | (14, 14, 1024) | 200,704 | 0\n",
      "res4b_branch2a | Conv2D | (1, 1, 1024, 256) | 262,144 | (14, 14, 256) | 50,176 | 51,380,224\n",
      "bn4b_branch2a | BatchNormalization | 0 | 0 | (14, 14, 256) | 50,176 | 0\n",
      "activation_322 | Activation | 0 | 0 | (14, 14, 256) | 50,176 | 0\n",
      "res4b_branch2b | Conv2D | (3, 3, 256, 256) | 589,824 | (14, 14, 256) | 50,176 | 115,605,504\n",
      "bn4b_branch2b | BatchNormalization | 0 | 0 | (14, 14, 256) | 50,176 | 0\n",
      "activation_323 | Activation | 0 | 0 | (14, 14, 256) | 50,176 | 0\n",
      "res4b_branch2c | Conv2D | (1, 1, 256, 1024) | 262,144 | (14, 14, 1024) | 200,704 | 51,380,224\n",
      "bn4b_branch2c | BatchNormalization | 0 | 0 | (14, 14, 1024) | 200,704 | 0\n",
      "add_39 | Add | 0 | 0 | (14, 14, 1024) | 200,704 | 0\n",
      "activation_324 | Activation | 0 | 0 | (14, 14, 1024) | 200,704 | 0\n",
      "res4c_branch2a | Conv2D | (1, 1, 1024, 256) | 262,144 | (14, 14, 256) | 50,176 | 51,380,224\n",
      "bn4c_branch2a | BatchNormalization | 0 | 0 | (14, 14, 256) | 50,176 | 0\n",
      "activation_325 | Activation | 0 | 0 | (14, 14, 256) | 50,176 | 0\n",
      "res4c_branch2b | Conv2D | (3, 3, 256, 256) | 589,824 | (14, 14, 256) | 50,176 | 115,605,504\n",
      "bn4c_branch2b | BatchNormalization | 0 | 0 | (14, 14, 256) | 50,176 | 0\n",
      "activation_326 | Activation | 0 | 0 | (14, 14, 256) | 50,176 | 0\n",
      "res4c_branch2c | Conv2D | (1, 1, 256, 1024) | 262,144 | (14, 14, 1024) | 200,704 | 51,380,224\n",
      "bn4c_branch2c | BatchNormalization | 0 | 0 | (14, 14, 1024) | 200,704 | 0\n",
      "add_40 | Add | 0 | 0 | (14, 14, 1024) | 200,704 | 0\n",
      "activation_327 | Activation | 0 | 0 | (14, 14, 1024) | 200,704 | 0\n",
      "res4d_branch2a | Conv2D | (1, 1, 1024, 256) | 262,144 | (14, 14, 256) | 50,176 | 51,380,224\n",
      "bn4d_branch2a | BatchNormalization | 0 | 0 | (14, 14, 256) | 50,176 | 0\n",
      "activation_328 | Activation | 0 | 0 | (14, 14, 256) | 50,176 | 0\n",
      "res4d_branch2b | Conv2D | (3, 3, 256, 256) | 589,824 | (14, 14, 256) | 50,176 | 115,605,504\n",
      "bn4d_branch2b | BatchNormalization | 0 | 0 | (14, 14, 256) | 50,176 | 0\n",
      "activation_329 | Activation | 0 | 0 | (14, 14, 256) | 50,176 | 0\n",
      "res4d_branch2c | Conv2D | (1, 1, 256, 1024) | 262,144 | (14, 14, 1024) | 200,704 | 51,380,224\n",
      "bn4d_branch2c | BatchNormalization | 0 | 0 | (14, 14, 1024) | 200,704 | 0\n",
      "add_41 | Add | 0 | 0 | (14, 14, 1024) | 200,704 | 0\n",
      "activation_330 | Activation | 0 | 0 | (14, 14, 1024) | 200,704 | 0\n",
      "res4e_branch2a | Conv2D | (1, 1, 1024, 256) | 262,144 | (14, 14, 256) | 50,176 | 51,380,224\n",
      "bn4e_branch2a | BatchNormalization | 0 | 0 | (14, 14, 256) | 50,176 | 0\n",
      "activation_331 | Activation | 0 | 0 | (14, 14, 256) | 50,176 | 0\n",
      "res4e_branch2b | Conv2D | (3, 3, 256, 256) | 589,824 | (14, 14, 256) | 50,176 | 115,605,504\n",
      "bn4e_branch2b | BatchNormalization | 0 | 0 | (14, 14, 256) | 50,176 | 0\n",
      "activation_332 | Activation | 0 | 0 | (14, 14, 256) | 50,176 | 0\n",
      "res4e_branch2c | Conv2D | (1, 1, 256, 1024) | 262,144 | (14, 14, 1024) | 200,704 | 51,380,224\n",
      "bn4e_branch2c | BatchNormalization | 0 | 0 | (14, 14, 1024) | 200,704 | 0\n",
      "add_42 | Add | 0 | 0 | (14, 14, 1024) | 200,704 | 0\n",
      "activation_333 | Activation | 0 | 0 | (14, 14, 1024) | 200,704 | 0\n",
      "res4f_branch2a | Conv2D | (1, 1, 1024, 256) | 262,144 | (14, 14, 256) | 50,176 | 51,380,224\n",
      "bn4f_branch2a | BatchNormalization | 0 | 0 | (14, 14, 256) | 50,176 | 0\n",
      "activation_334 | Activation | 0 | 0 | (14, 14, 256) | 50,176 | 0\n",
      "res4f_branch2b | Conv2D | (3, 3, 256, 256) | 589,824 | (14, 14, 256) | 50,176 | 115,605,504\n",
      "bn4f_branch2b | BatchNormalization | 0 | 0 | (14, 14, 256) | 50,176 | 0\n",
      "activation_335 | Activation | 0 | 0 | (14, 14, 256) | 50,176 | 0\n",
      "res4f_branch2c | Conv2D | (1, 1, 256, 1024) | 262,144 | (14, 14, 1024) | 200,704 | 51,380,224\n",
      "bn4f_branch2c | BatchNormalization | 0 | 0 | (14, 14, 1024) | 200,704 | 0\n",
      "add_43 | Add | 0 | 0 | (14, 14, 1024) | 200,704 | 0\n",
      "activation_336 | Activation | 0 | 0 | (14, 14, 1024) | 200,704 | 0\n",
      "res5a_branch2a | Conv2D | (1, 1, 1024, 512) | 524,288 | (7, 7, 512) | 25,088 | 25,690,112\n",
      "bn5a_branch2a | BatchNormalization | 0 | 0 | (7, 7, 512) | 25,088 | 0\n",
      "activation_337 | Activation | 0 | 0 | (7, 7, 512) | 25,088 | 0\n",
      "res5a_branch2b | Conv2D | (3, 3, 512, 512) | 2,359,296 | (7, 7, 512) | 25,088 | 115,605,504\n",
      "bn5a_branch2b | BatchNormalization | 0 | 0 | (7, 7, 512) | 25,088 | 0\n",
      "activation_338 | Activation | 0 | 0 | (7, 7, 512) | 25,088 | 0\n",
      "res5a_branch2c | Conv2D | (1, 1, 512, 2048) | 1,048,576 | (7, 7, 2048) | 100,352 | 51,380,224\n",
      "res5a_branch1 | Conv2D | (1, 1, 1024, 2048) | 2,097,152 | (7, 7, 2048) | 100,352 | 102,760,448\n",
      "bn5a_branch2c | BatchNormalization | 0 | 0 | (7, 7, 2048) | 100,352 | 0\n",
      "bn5a_branch1 | BatchNormalization | 0 | 0 | (7, 7, 2048) | 100,352 | 0\n",
      "add_44 | Add | 0 | 0 | (7, 7, 2048) | 100,352 | 0\n",
      "activation_339 | Activation | 0 | 0 | (7, 7, 2048) | 100,352 | 0\n",
      "res5b_branch2a | Conv2D | (1, 1, 2048, 512) | 1,048,576 | (7, 7, 512) | 25,088 | 51,380,224\n",
      "bn5b_branch2a | BatchNormalization | 0 | 0 | (7, 7, 512) | 25,088 | 0\n",
      "activation_340 | Activation | 0 | 0 | (7, 7, 512) | 25,088 | 0\n",
      "res5b_branch2b | Conv2D | (3, 3, 512, 512) | 2,359,296 | (7, 7, 512) | 25,088 | 115,605,504\n",
      "bn5b_branch2b | BatchNormalization | 0 | 0 | (7, 7, 512) | 25,088 | 0\n",
      "activation_341 | Activation | 0 | 0 | (7, 7, 512) | 25,088 | 0\n",
      "res5b_branch2c | Conv2D | (1, 1, 512, 2048) | 1,048,576 | (7, 7, 2048) | 100,352 | 51,380,224\n",
      "bn5b_branch2c | BatchNormalization | 0 | 0 | (7, 7, 2048) | 100,352 | 0\n",
      "add_45 | Add | 0 | 0 | (7, 7, 2048) | 100,352 | 0\n",
      "activation_342 | Activation | 0 | 0 | (7, 7, 2048) | 100,352 | 0\n",
      "res5c_branch2a | Conv2D | (1, 1, 2048, 512) | 1,048,576 | (7, 7, 512) | 25,088 | 51,380,224\n",
      "bn5c_branch2a | BatchNormalization | 0 | 0 | (7, 7, 512) | 25,088 | 0\n",
      "activation_343 | Activation | 0 | 0 | (7, 7, 512) | 25,088 | 0\n",
      "res5c_branch2b | Conv2D | (3, 3, 512, 512) | 2,359,296 | (7, 7, 512) | 25,088 | 115,605,504\n",
      "bn5c_branch2b | BatchNormalization | 0 | 0 | (7, 7, 512) | 25,088 | 0\n",
      "activation_344 | Activation | 0 | 0 | (7, 7, 512) | 25,088 | 0\n",
      "res5c_branch2c | Conv2D | (1, 1, 512, 2048) | 1,048,576 | (7, 7, 2048) | 100,352 | 51,380,224\n",
      "bn5c_branch2c | BatchNormalization | 0 | 0 | (7, 7, 2048) | 100,352 | 0\n",
      "add_46 | Add | 0 | 0 | (7, 7, 2048) | 100,352 | 0\n",
      "activation_345 | Activation | 0 | 0 | (7, 7, 2048) | 100,352 | 0\n",
      "avg_pool | AveragePooling2D | 0 | 0 | (1, 1, 2048) | 2,048 | 0\n",
      "flatten_1 | Flatten | 0 | 0 | (2048,) | 2,048 | 0\n",
      "fc1000 | Dense | (2048, 1000) | 2,048,000 | (1000,) | 1,000 | 2,048,000\n",
      "- | - | - | - | - | - | -\n",
      "- | - | - | Kernel Mem (Total) | - | Output Mem (Total) | FLOPS (Total)\n",
      "Summary | - | - | 25,502,912 | - | 35,599,016 | 3,834,331,136\n",
      "\n",
      "----------------------\n",
      "\n",
      "Model Name: resnet50\n",
      "Overall FLOPS: 3834 MFLOPS\n",
      "Overall Params: 58 MParams\n",
      "Operational Intensity = 16 FLOPS/Byte\n"
     ]
    }
   ],
   "source": [
    "intensity(ResNet50())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer Name | Layer Type | Kernel Size | Kernel Mem | Output Size | Output Mem | FLOPS\n",
      "--- | --- | --- | --- | --- | --- | ---\n",
      "input_6 | InputLayer | 0 | 0 | (299, 299, 3) | 268,203 | 0\n",
      "conv2d_206 | Conv2D | (3, 3, 3, 32) | 864 | (149, 149, 32) | 710,432 | 19,181,664\n",
      "batch_normalization_254 | BatchNormalization | 0 | 0 | (149, 149, 32) | 710,432 | 0\n",
      "activation_203 | Activation | 0 | 0 | (149, 149, 32) | 710,432 | 0\n",
      "conv2d_207 | Conv2D | (3, 3, 32, 32) | 9,216 | (147, 147, 32) | 691,488 | 199,148,544\n",
      "batch_normalization_255 | BatchNormalization | 0 | 0 | (147, 147, 32) | 691,488 | 0\n",
      "activation_204 | Activation | 0 | 0 | (147, 147, 32) | 691,488 | 0\n",
      "conv2d_208 | Conv2D | (3, 3, 32, 64) | 18,432 | (147, 147, 64) | 1,382,976 | 398,297,088\n",
      "batch_normalization_256 | BatchNormalization | 0 | 0 | (147, 147, 64) | 1,382,976 | 0\n",
      "activation_205 | Activation | 0 | 0 | (147, 147, 64) | 1,382,976 | 0\n",
      "max_pooling2d_5 | MaxPooling2D | 0 | 0 | (73, 73, 64) | 341,056 | 0\n",
      "conv2d_209 | Conv2D | (1, 1, 64, 80) | 5,120 | (73, 73, 80) | 426,320 | 27,284,480\n",
      "batch_normalization_257 | BatchNormalization | 0 | 0 | (73, 73, 80) | 426,320 | 0\n",
      "activation_206 | Activation | 0 | 0 | (73, 73, 80) | 426,320 | 0\n",
      "conv2d_210 | Conv2D | (3, 3, 80, 192) | 138,240 | (71, 71, 192) | 967,872 | 696,867,840\n",
      "batch_normalization_258 | BatchNormalization | 0 | 0 | (71, 71, 192) | 967,872 | 0\n",
      "activation_207 | Activation | 0 | 0 | (71, 71, 192) | 967,872 | 0\n",
      "max_pooling2d_6 | MaxPooling2D | 0 | 0 | (35, 35, 192) | 235,200 | 0\n",
      "conv2d_214 | Conv2D | (1, 1, 192, 64) | 12,288 | (35, 35, 64) | 78,400 | 15,052,800\n",
      "batch_normalization_262 | BatchNormalization | 0 | 0 | (35, 35, 64) | 78,400 | 0\n",
      "activation_211 | Activation | 0 | 0 | (35, 35, 64) | 78,400 | 0\n",
      "conv2d_212 | Conv2D | (1, 1, 192, 48) | 9,216 | (35, 35, 48) | 58,800 | 11,289,600\n",
      "conv2d_215 | Conv2D | (3, 3, 64, 96) | 55,296 | (35, 35, 96) | 117,600 | 67,737,600\n",
      "batch_normalization_260 | BatchNormalization | 0 | 0 | (35, 35, 48) | 58,800 | 0\n",
      "batch_normalization_263 | BatchNormalization | 0 | 0 | (35, 35, 96) | 117,600 | 0\n",
      "activation_209 | Activation | 0 | 0 | (35, 35, 48) | 58,800 | 0\n",
      "activation_212 | Activation | 0 | 0 | (35, 35, 96) | 117,600 | 0\n",
      "average_pooling2d_10 | AveragePooling2D | 0 | 0 | (35, 35, 192) | 235,200 | 0\n",
      "conv2d_211 | Conv2D | (1, 1, 192, 64) | 12,288 | (35, 35, 64) | 78,400 | 15,052,800\n",
      "conv2d_213 | Conv2D | (5, 5, 48, 64) | 76,800 | (35, 35, 64) | 78,400 | 94,080,000\n",
      "conv2d_216 | Conv2D | (3, 3, 96, 96) | 82,944 | (35, 35, 96) | 117,600 | 101,606,400\n",
      "conv2d_217 | Conv2D | (1, 1, 192, 32) | 6,144 | (35, 35, 32) | 39,200 | 7,526,400\n",
      "batch_normalization_259 | BatchNormalization | 0 | 0 | (35, 35, 64) | 78,400 | 0\n",
      "batch_normalization_261 | BatchNormalization | 0 | 0 | (35, 35, 64) | 78,400 | 0\n",
      "batch_normalization_264 | BatchNormalization | 0 | 0 | (35, 35, 96) | 117,600 | 0\n",
      "batch_normalization_265 | BatchNormalization | 0 | 0 | (35, 35, 32) | 39,200 | 0\n",
      "activation_208 | Activation | 0 | 0 | (35, 35, 64) | 78,400 | 0\n",
      "activation_210 | Activation | 0 | 0 | (35, 35, 64) | 78,400 | 0\n",
      "activation_213 | Activation | 0 | 0 | (35, 35, 96) | 117,600 | 0\n",
      "activation_214 | Activation | 0 | 0 | (35, 35, 32) | 39,200 | 0\n",
      "mixed0 | Concatenate | 0 | 0 | (35, 35, 256) | 313,600 | 0\n",
      "conv2d_221 | Conv2D | (1, 1, 256, 64) | 16,384 | (35, 35, 64) | 78,400 | 20,070,400\n",
      "batch_normalization_269 | BatchNormalization | 0 | 0 | (35, 35, 64) | 78,400 | 0\n",
      "activation_218 | Activation | 0 | 0 | (35, 35, 64) | 78,400 | 0\n",
      "conv2d_219 | Conv2D | (1, 1, 256, 48) | 12,288 | (35, 35, 48) | 58,800 | 15,052,800\n",
      "conv2d_222 | Conv2D | (3, 3, 64, 96) | 55,296 | (35, 35, 96) | 117,600 | 67,737,600\n",
      "batch_normalization_267 | BatchNormalization | 0 | 0 | (35, 35, 48) | 58,800 | 0\n",
      "batch_normalization_270 | BatchNormalization | 0 | 0 | (35, 35, 96) | 117,600 | 0\n",
      "activation_216 | Activation | 0 | 0 | (35, 35, 48) | 58,800 | 0\n",
      "activation_219 | Activation | 0 | 0 | (35, 35, 96) | 117,600 | 0\n",
      "average_pooling2d_11 | AveragePooling2D | 0 | 0 | (35, 35, 256) | 313,600 | 0\n",
      "conv2d_218 | Conv2D | (1, 1, 256, 64) | 16,384 | (35, 35, 64) | 78,400 | 20,070,400\n",
      "conv2d_220 | Conv2D | (5, 5, 48, 64) | 76,800 | (35, 35, 64) | 78,400 | 94,080,000\n",
      "conv2d_223 | Conv2D | (3, 3, 96, 96) | 82,944 | (35, 35, 96) | 117,600 | 101,606,400\n",
      "conv2d_224 | Conv2D | (1, 1, 256, 64) | 16,384 | (35, 35, 64) | 78,400 | 20,070,400\n",
      "batch_normalization_266 | BatchNormalization | 0 | 0 | (35, 35, 64) | 78,400 | 0\n",
      "batch_normalization_268 | BatchNormalization | 0 | 0 | (35, 35, 64) | 78,400 | 0\n",
      "batch_normalization_271 | BatchNormalization | 0 | 0 | (35, 35, 96) | 117,600 | 0\n",
      "batch_normalization_272 | BatchNormalization | 0 | 0 | (35, 35, 64) | 78,400 | 0\n",
      "activation_215 | Activation | 0 | 0 | (35, 35, 64) | 78,400 | 0\n",
      "activation_217 | Activation | 0 | 0 | (35, 35, 64) | 78,400 | 0\n",
      "activation_220 | Activation | 0 | 0 | (35, 35, 96) | 117,600 | 0\n",
      "activation_221 | Activation | 0 | 0 | (35, 35, 64) | 78,400 | 0\n",
      "mixed1 | Concatenate | 0 | 0 | (35, 35, 288) | 352,800 | 0\n",
      "conv2d_228 | Conv2D | (1, 1, 288, 64) | 18,432 | (35, 35, 64) | 78,400 | 22,579,200\n",
      "batch_normalization_276 | BatchNormalization | 0 | 0 | (35, 35, 64) | 78,400 | 0\n",
      "activation_225 | Activation | 0 | 0 | (35, 35, 64) | 78,400 | 0\n",
      "conv2d_226 | Conv2D | (1, 1, 288, 48) | 13,824 | (35, 35, 48) | 58,800 | 16,934,400\n",
      "conv2d_229 | Conv2D | (3, 3, 64, 96) | 55,296 | (35, 35, 96) | 117,600 | 67,737,600\n",
      "batch_normalization_274 | BatchNormalization | 0 | 0 | (35, 35, 48) | 58,800 | 0\n",
      "batch_normalization_277 | BatchNormalization | 0 | 0 | (35, 35, 96) | 117,600 | 0\n",
      "activation_223 | Activation | 0 | 0 | (35, 35, 48) | 58,800 | 0\n",
      "activation_226 | Activation | 0 | 0 | (35, 35, 96) | 117,600 | 0\n",
      "average_pooling2d_12 | AveragePooling2D | 0 | 0 | (35, 35, 288) | 352,800 | 0\n",
      "conv2d_225 | Conv2D | (1, 1, 288, 64) | 18,432 | (35, 35, 64) | 78,400 | 22,579,200\n",
      "conv2d_227 | Conv2D | (5, 5, 48, 64) | 76,800 | (35, 35, 64) | 78,400 | 94,080,000\n",
      "conv2d_230 | Conv2D | (3, 3, 96, 96) | 82,944 | (35, 35, 96) | 117,600 | 101,606,400\n",
      "conv2d_231 | Conv2D | (1, 1, 288, 64) | 18,432 | (35, 35, 64) | 78,400 | 22,579,200\n",
      "batch_normalization_273 | BatchNormalization | 0 | 0 | (35, 35, 64) | 78,400 | 0\n",
      "batch_normalization_275 | BatchNormalization | 0 | 0 | (35, 35, 64) | 78,400 | 0\n",
      "batch_normalization_278 | BatchNormalization | 0 | 0 | (35, 35, 96) | 117,600 | 0\n",
      "batch_normalization_279 | BatchNormalization | 0 | 0 | (35, 35, 64) | 78,400 | 0\n",
      "activation_222 | Activation | 0 | 0 | (35, 35, 64) | 78,400 | 0\n",
      "activation_224 | Activation | 0 | 0 | (35, 35, 64) | 78,400 | 0\n",
      "activation_227 | Activation | 0 | 0 | (35, 35, 96) | 117,600 | 0\n",
      "activation_228 | Activation | 0 | 0 | (35, 35, 64) | 78,400 | 0\n",
      "mixed2 | Concatenate | 0 | 0 | (35, 35, 288) | 352,800 | 0\n",
      "conv2d_233 | Conv2D | (1, 1, 288, 64) | 18,432 | (35, 35, 64) | 78,400 | 22,579,200\n",
      "batch_normalization_281 | BatchNormalization | 0 | 0 | (35, 35, 64) | 78,400 | 0\n",
      "activation_230 | Activation | 0 | 0 | (35, 35, 64) | 78,400 | 0\n",
      "conv2d_234 | Conv2D | (3, 3, 64, 96) | 55,296 | (35, 35, 96) | 117,600 | 67,737,600\n",
      "batch_normalization_282 | BatchNormalization | 0 | 0 | (35, 35, 96) | 117,600 | 0\n",
      "activation_231 | Activation | 0 | 0 | (35, 35, 96) | 117,600 | 0\n",
      "conv2d_232 | Conv2D | (3, 3, 288, 384) | 995,328 | (17, 17, 384) | 110,976 | 287,649,792\n",
      "conv2d_235 | Conv2D | (3, 3, 96, 96) | 82,944 | (17, 17, 96) | 27,744 | 23,970,816\n",
      "batch_normalization_280 | BatchNormalization | 0 | 0 | (17, 17, 384) | 110,976 | 0\n",
      "batch_normalization_283 | BatchNormalization | 0 | 0 | (17, 17, 96) | 27,744 | 0\n",
      "activation_229 | Activation | 0 | 0 | (17, 17, 384) | 110,976 | 0\n",
      "activation_232 | Activation | 0 | 0 | (17, 17, 96) | 27,744 | 0\n",
      "max_pooling2d_7 | MaxPooling2D | 0 | 0 | (17, 17, 288) | 83,232 | 0\n",
      "mixed3 | Concatenate | 0 | 0 | (17, 17, 768) | 221,952 | 0\n",
      "conv2d_240 | Conv2D | (1, 1, 768, 128) | 98,304 | (17, 17, 128) | 36,992 | 28,409,856\n",
      "batch_normalization_288 | BatchNormalization | 0 | 0 | (17, 17, 128) | 36,992 | 0\n",
      "activation_237 | Activation | 0 | 0 | (17, 17, 128) | 36,992 | 0\n",
      "conv2d_241 | Conv2D | (7, 1, 128, 128) | 114,688 | (17, 17, 128) | 36,992 | 33,144,832\n",
      "batch_normalization_289 | BatchNormalization | 0 | 0 | (17, 17, 128) | 36,992 | 0\n",
      "activation_238 | Activation | 0 | 0 | (17, 17, 128) | 36,992 | 0\n",
      "conv2d_237 | Conv2D | (1, 1, 768, 128) | 98,304 | (17, 17, 128) | 36,992 | 28,409,856\n",
      "conv2d_242 | Conv2D | (1, 7, 128, 128) | 114,688 | (17, 17, 128) | 36,992 | 33,144,832\n",
      "batch_normalization_285 | BatchNormalization | 0 | 0 | (17, 17, 128) | 36,992 | 0\n",
      "batch_normalization_290 | BatchNormalization | 0 | 0 | (17, 17, 128) | 36,992 | 0\n",
      "activation_234 | Activation | 0 | 0 | (17, 17, 128) | 36,992 | 0\n",
      "activation_239 | Activation | 0 | 0 | (17, 17, 128) | 36,992 | 0\n",
      "conv2d_238 | Conv2D | (1, 7, 128, 128) | 114,688 | (17, 17, 128) | 36,992 | 33,144,832\n",
      "conv2d_243 | Conv2D | (7, 1, 128, 128) | 114,688 | (17, 17, 128) | 36,992 | 33,144,832\n",
      "batch_normalization_286 | BatchNormalization | 0 | 0 | (17, 17, 128) | 36,992 | 0\n",
      "batch_normalization_291 | BatchNormalization | 0 | 0 | (17, 17, 128) | 36,992 | 0\n",
      "activation_235 | Activation | 0 | 0 | (17, 17, 128) | 36,992 | 0\n",
      "activation_240 | Activation | 0 | 0 | (17, 17, 128) | 36,992 | 0\n",
      "average_pooling2d_13 | AveragePooling2D | 0 | 0 | (17, 17, 768) | 221,952 | 0\n",
      "conv2d_236 | Conv2D | (1, 1, 768, 192) | 147,456 | (17, 17, 192) | 55,488 | 42,614,784\n",
      "conv2d_239 | Conv2D | (7, 1, 128, 192) | 172,032 | (17, 17, 192) | 55,488 | 49,717,248\n",
      "conv2d_244 | Conv2D | (1, 7, 128, 192) | 172,032 | (17, 17, 192) | 55,488 | 49,717,248\n",
      "conv2d_245 | Conv2D | (1, 1, 768, 192) | 147,456 | (17, 17, 192) | 55,488 | 42,614,784\n",
      "batch_normalization_284 | BatchNormalization | 0 | 0 | (17, 17, 192) | 55,488 | 0\n",
      "batch_normalization_287 | BatchNormalization | 0 | 0 | (17, 17, 192) | 55,488 | 0\n",
      "batch_normalization_292 | BatchNormalization | 0 | 0 | (17, 17, 192) | 55,488 | 0\n",
      "batch_normalization_293 | BatchNormalization | 0 | 0 | (17, 17, 192) | 55,488 | 0\n",
      "activation_233 | Activation | 0 | 0 | (17, 17, 192) | 55,488 | 0\n",
      "activation_236 | Activation | 0 | 0 | (17, 17, 192) | 55,488 | 0\n",
      "activation_241 | Activation | 0 | 0 | (17, 17, 192) | 55,488 | 0\n",
      "activation_242 | Activation | 0 | 0 | (17, 17, 192) | 55,488 | 0\n",
      "mixed4 | Concatenate | 0 | 0 | (17, 17, 768) | 221,952 | 0\n",
      "conv2d_250 | Conv2D | (1, 1, 768, 160) | 122,880 | (17, 17, 160) | 46,240 | 35,512,320\n",
      "batch_normalization_298 | BatchNormalization | 0 | 0 | (17, 17, 160) | 46,240 | 0\n",
      "activation_247 | Activation | 0 | 0 | (17, 17, 160) | 46,240 | 0\n",
      "conv2d_251 | Conv2D | (7, 1, 160, 160) | 179,200 | (17, 17, 160) | 46,240 | 51,788,800\n",
      "batch_normalization_299 | BatchNormalization | 0 | 0 | (17, 17, 160) | 46,240 | 0\n",
      "activation_248 | Activation | 0 | 0 | (17, 17, 160) | 46,240 | 0\n",
      "conv2d_247 | Conv2D | (1, 1, 768, 160) | 122,880 | (17, 17, 160) | 46,240 | 35,512,320\n",
      "conv2d_252 | Conv2D | (1, 7, 160, 160) | 179,200 | (17, 17, 160) | 46,240 | 51,788,800\n",
      "batch_normalization_295 | BatchNormalization | 0 | 0 | (17, 17, 160) | 46,240 | 0\n",
      "batch_normalization_300 | BatchNormalization | 0 | 0 | (17, 17, 160) | 46,240 | 0\n",
      "activation_244 | Activation | 0 | 0 | (17, 17, 160) | 46,240 | 0\n",
      "activation_249 | Activation | 0 | 0 | (17, 17, 160) | 46,240 | 0\n",
      "conv2d_248 | Conv2D | (1, 7, 160, 160) | 179,200 | (17, 17, 160) | 46,240 | 51,788,800\n",
      "conv2d_253 | Conv2D | (7, 1, 160, 160) | 179,200 | (17, 17, 160) | 46,240 | 51,788,800\n",
      "batch_normalization_296 | BatchNormalization | 0 | 0 | (17, 17, 160) | 46,240 | 0\n",
      "batch_normalization_301 | BatchNormalization | 0 | 0 | (17, 17, 160) | 46,240 | 0\n",
      "activation_245 | Activation | 0 | 0 | (17, 17, 160) | 46,240 | 0\n",
      "activation_250 | Activation | 0 | 0 | (17, 17, 160) | 46,240 | 0\n",
      "average_pooling2d_14 | AveragePooling2D | 0 | 0 | (17, 17, 768) | 221,952 | 0\n",
      "conv2d_246 | Conv2D | (1, 1, 768, 192) | 147,456 | (17, 17, 192) | 55,488 | 42,614,784\n",
      "conv2d_249 | Conv2D | (7, 1, 160, 192) | 215,040 | (17, 17, 192) | 55,488 | 62,146,560\n",
      "conv2d_254 | Conv2D | (1, 7, 160, 192) | 215,040 | (17, 17, 192) | 55,488 | 62,146,560\n",
      "conv2d_255 | Conv2D | (1, 1, 768, 192) | 147,456 | (17, 17, 192) | 55,488 | 42,614,784\n",
      "batch_normalization_294 | BatchNormalization | 0 | 0 | (17, 17, 192) | 55,488 | 0\n",
      "batch_normalization_297 | BatchNormalization | 0 | 0 | (17, 17, 192) | 55,488 | 0\n",
      "batch_normalization_302 | BatchNormalization | 0 | 0 | (17, 17, 192) | 55,488 | 0\n",
      "batch_normalization_303 | BatchNormalization | 0 | 0 | (17, 17, 192) | 55,488 | 0\n",
      "activation_243 | Activation | 0 | 0 | (17, 17, 192) | 55,488 | 0\n",
      "activation_246 | Activation | 0 | 0 | (17, 17, 192) | 55,488 | 0\n",
      "activation_251 | Activation | 0 | 0 | (17, 17, 192) | 55,488 | 0\n",
      "activation_252 | Activation | 0 | 0 | (17, 17, 192) | 55,488 | 0\n",
      "mixed5 | Concatenate | 0 | 0 | (17, 17, 768) | 221,952 | 0\n",
      "conv2d_260 | Conv2D | (1, 1, 768, 160) | 122,880 | (17, 17, 160) | 46,240 | 35,512,320\n",
      "batch_normalization_308 | BatchNormalization | 0 | 0 | (17, 17, 160) | 46,240 | 0\n",
      "activation_257 | Activation | 0 | 0 | (17, 17, 160) | 46,240 | 0\n",
      "conv2d_261 | Conv2D | (7, 1, 160, 160) | 179,200 | (17, 17, 160) | 46,240 | 51,788,800\n",
      "batch_normalization_309 | BatchNormalization | 0 | 0 | (17, 17, 160) | 46,240 | 0\n",
      "activation_258 | Activation | 0 | 0 | (17, 17, 160) | 46,240 | 0\n",
      "conv2d_257 | Conv2D | (1, 1, 768, 160) | 122,880 | (17, 17, 160) | 46,240 | 35,512,320\n",
      "conv2d_262 | Conv2D | (1, 7, 160, 160) | 179,200 | (17, 17, 160) | 46,240 | 51,788,800\n",
      "batch_normalization_305 | BatchNormalization | 0 | 0 | (17, 17, 160) | 46,240 | 0\n",
      "batch_normalization_310 | BatchNormalization | 0 | 0 | (17, 17, 160) | 46,240 | 0\n",
      "activation_254 | Activation | 0 | 0 | (17, 17, 160) | 46,240 | 0\n",
      "activation_259 | Activation | 0 | 0 | (17, 17, 160) | 46,240 | 0\n",
      "conv2d_258 | Conv2D | (1, 7, 160, 160) | 179,200 | (17, 17, 160) | 46,240 | 51,788,800\n",
      "conv2d_263 | Conv2D | (7, 1, 160, 160) | 179,200 | (17, 17, 160) | 46,240 | 51,788,800\n",
      "batch_normalization_306 | BatchNormalization | 0 | 0 | (17, 17, 160) | 46,240 | 0\n",
      "batch_normalization_311 | BatchNormalization | 0 | 0 | (17, 17, 160) | 46,240 | 0\n",
      "activation_255 | Activation | 0 | 0 | (17, 17, 160) | 46,240 | 0\n",
      "activation_260 | Activation | 0 | 0 | (17, 17, 160) | 46,240 | 0\n",
      "average_pooling2d_15 | AveragePooling2D | 0 | 0 | (17, 17, 768) | 221,952 | 0\n",
      "conv2d_256 | Conv2D | (1, 1, 768, 192) | 147,456 | (17, 17, 192) | 55,488 | 42,614,784\n",
      "conv2d_259 | Conv2D | (7, 1, 160, 192) | 215,040 | (17, 17, 192) | 55,488 | 62,146,560\n",
      "conv2d_264 | Conv2D | (1, 7, 160, 192) | 215,040 | (17, 17, 192) | 55,488 | 62,146,560\n",
      "conv2d_265 | Conv2D | (1, 1, 768, 192) | 147,456 | (17, 17, 192) | 55,488 | 42,614,784\n",
      "batch_normalization_304 | BatchNormalization | 0 | 0 | (17, 17, 192) | 55,488 | 0\n",
      "batch_normalization_307 | BatchNormalization | 0 | 0 | (17, 17, 192) | 55,488 | 0\n",
      "batch_normalization_312 | BatchNormalization | 0 | 0 | (17, 17, 192) | 55,488 | 0\n",
      "batch_normalization_313 | BatchNormalization | 0 | 0 | (17, 17, 192) | 55,488 | 0\n",
      "activation_253 | Activation | 0 | 0 | (17, 17, 192) | 55,488 | 0\n",
      "activation_256 | Activation | 0 | 0 | (17, 17, 192) | 55,488 | 0\n",
      "activation_261 | Activation | 0 | 0 | (17, 17, 192) | 55,488 | 0\n",
      "activation_262 | Activation | 0 | 0 | (17, 17, 192) | 55,488 | 0\n",
      "mixed6 | Concatenate | 0 | 0 | (17, 17, 768) | 221,952 | 0\n",
      "conv2d_270 | Conv2D | (1, 1, 768, 192) | 147,456 | (17, 17, 192) | 55,488 | 42,614,784\n",
      "batch_normalization_318 | BatchNormalization | 0 | 0 | (17, 17, 192) | 55,488 | 0\n",
      "activation_267 | Activation | 0 | 0 | (17, 17, 192) | 55,488 | 0\n",
      "conv2d_271 | Conv2D | (7, 1, 192, 192) | 258,048 | (17, 17, 192) | 55,488 | 74,575,872\n",
      "batch_normalization_319 | BatchNormalization | 0 | 0 | (17, 17, 192) | 55,488 | 0\n",
      "activation_268 | Activation | 0 | 0 | (17, 17, 192) | 55,488 | 0\n",
      "conv2d_267 | Conv2D | (1, 1, 768, 192) | 147,456 | (17, 17, 192) | 55,488 | 42,614,784\n",
      "conv2d_272 | Conv2D | (1, 7, 192, 192) | 258,048 | (17, 17, 192) | 55,488 | 74,575,872\n",
      "batch_normalization_315 | BatchNormalization | 0 | 0 | (17, 17, 192) | 55,488 | 0\n",
      "batch_normalization_320 | BatchNormalization | 0 | 0 | (17, 17, 192) | 55,488 | 0\n",
      "activation_264 | Activation | 0 | 0 | (17, 17, 192) | 55,488 | 0\n",
      "activation_269 | Activation | 0 | 0 | (17, 17, 192) | 55,488 | 0\n",
      "conv2d_268 | Conv2D | (1, 7, 192, 192) | 258,048 | (17, 17, 192) | 55,488 | 74,575,872\n",
      "conv2d_273 | Conv2D | (7, 1, 192, 192) | 258,048 | (17, 17, 192) | 55,488 | 74,575,872\n",
      "batch_normalization_316 | BatchNormalization | 0 | 0 | (17, 17, 192) | 55,488 | 0\n",
      "batch_normalization_321 | BatchNormalization | 0 | 0 | (17, 17, 192) | 55,488 | 0\n",
      "activation_265 | Activation | 0 | 0 | (17, 17, 192) | 55,488 | 0\n",
      "activation_270 | Activation | 0 | 0 | (17, 17, 192) | 55,488 | 0\n",
      "average_pooling2d_16 | AveragePooling2D | 0 | 0 | (17, 17, 768) | 221,952 | 0\n",
      "conv2d_266 | Conv2D | (1, 1, 768, 192) | 147,456 | (17, 17, 192) | 55,488 | 42,614,784\n",
      "conv2d_269 | Conv2D | (7, 1, 192, 192) | 258,048 | (17, 17, 192) | 55,488 | 74,575,872\n",
      "conv2d_274 | Conv2D | (1, 7, 192, 192) | 258,048 | (17, 17, 192) | 55,488 | 74,575,872\n",
      "conv2d_275 | Conv2D | (1, 1, 768, 192) | 147,456 | (17, 17, 192) | 55,488 | 42,614,784\n",
      "batch_normalization_314 | BatchNormalization | 0 | 0 | (17, 17, 192) | 55,488 | 0\n",
      "batch_normalization_317 | BatchNormalization | 0 | 0 | (17, 17, 192) | 55,488 | 0\n",
      "batch_normalization_322 | BatchNormalization | 0 | 0 | (17, 17, 192) | 55,488 | 0\n",
      "batch_normalization_323 | BatchNormalization | 0 | 0 | (17, 17, 192) | 55,488 | 0\n",
      "activation_263 | Activation | 0 | 0 | (17, 17, 192) | 55,488 | 0\n",
      "activation_266 | Activation | 0 | 0 | (17, 17, 192) | 55,488 | 0\n",
      "activation_271 | Activation | 0 | 0 | (17, 17, 192) | 55,488 | 0\n",
      "activation_272 | Activation | 0 | 0 | (17, 17, 192) | 55,488 | 0\n",
      "mixed7 | Concatenate | 0 | 0 | (17, 17, 768) | 221,952 | 0\n",
      "conv2d_278 | Conv2D | (1, 1, 768, 192) | 147,456 | (17, 17, 192) | 55,488 | 42,614,784\n",
      "batch_normalization_326 | BatchNormalization | 0 | 0 | (17, 17, 192) | 55,488 | 0\n",
      "activation_275 | Activation | 0 | 0 | (17, 17, 192) | 55,488 | 0\n",
      "conv2d_279 | Conv2D | (1, 7, 192, 192) | 258,048 | (17, 17, 192) | 55,488 | 74,575,872\n",
      "batch_normalization_327 | BatchNormalization | 0 | 0 | (17, 17, 192) | 55,488 | 0\n",
      "activation_276 | Activation | 0 | 0 | (17, 17, 192) | 55,488 | 0\n",
      "conv2d_276 | Conv2D | (1, 1, 768, 192) | 147,456 | (17, 17, 192) | 55,488 | 42,614,784\n",
      "conv2d_280 | Conv2D | (7, 1, 192, 192) | 258,048 | (17, 17, 192) | 55,488 | 74,575,872\n",
      "batch_normalization_324 | BatchNormalization | 0 | 0 | (17, 17, 192) | 55,488 | 0\n",
      "batch_normalization_328 | BatchNormalization | 0 | 0 | (17, 17, 192) | 55,488 | 0\n",
      "activation_273 | Activation | 0 | 0 | (17, 17, 192) | 55,488 | 0\n",
      "activation_277 | Activation | 0 | 0 | (17, 17, 192) | 55,488 | 0\n",
      "conv2d_277 | Conv2D | (3, 3, 192, 320) | 552,960 | (8, 8, 320) | 20,480 | 35,389,440\n",
      "conv2d_281 | Conv2D | (3, 3, 192, 192) | 331,776 | (8, 8, 192) | 12,288 | 21,233,664\n",
      "batch_normalization_325 | BatchNormalization | 0 | 0 | (8, 8, 320) | 20,480 | 0\n",
      "batch_normalization_329 | BatchNormalization | 0 | 0 | (8, 8, 192) | 12,288 | 0\n",
      "activation_274 | Activation | 0 | 0 | (8, 8, 320) | 20,480 | 0\n",
      "activation_278 | Activation | 0 | 0 | (8, 8, 192) | 12,288 | 0\n",
      "max_pooling2d_8 | MaxPooling2D | 0 | 0 | (8, 8, 768) | 49,152 | 0\n",
      "mixed8 | Concatenate | 0 | 0 | (8, 8, 1280) | 81,920 | 0\n",
      "conv2d_286 | Conv2D | (1, 1, 1280, 448) | 573,440 | (8, 8, 448) | 28,672 | 36,700,160\n",
      "batch_normalization_334 | BatchNormalization | 0 | 0 | (8, 8, 448) | 28,672 | 0\n",
      "activation_283 | Activation | 0 | 0 | (8, 8, 448) | 28,672 | 0\n",
      "conv2d_283 | Conv2D | (1, 1, 1280, 384) | 491,520 | (8, 8, 384) | 24,576 | 31,457,280\n",
      "conv2d_287 | Conv2D | (3, 3, 448, 384) | 1,548,288 | (8, 8, 384) | 24,576 | 99,090,432\n",
      "batch_normalization_331 | BatchNormalization | 0 | 0 | (8, 8, 384) | 24,576 | 0\n",
      "batch_normalization_335 | BatchNormalization | 0 | 0 | (8, 8, 384) | 24,576 | 0\n",
      "activation_280 | Activation | 0 | 0 | (8, 8, 384) | 24,576 | 0\n",
      "activation_284 | Activation | 0 | 0 | (8, 8, 384) | 24,576 | 0\n",
      "conv2d_284 | Conv2D | (1, 3, 384, 384) | 442,368 | (8, 8, 384) | 24,576 | 28,311,552\n",
      "conv2d_285 | Conv2D | (3, 1, 384, 384) | 442,368 | (8, 8, 384) | 24,576 | 28,311,552\n",
      "conv2d_288 | Conv2D | (1, 3, 384, 384) | 442,368 | (8, 8, 384) | 24,576 | 28,311,552\n",
      "conv2d_289 | Conv2D | (3, 1, 384, 384) | 442,368 | (8, 8, 384) | 24,576 | 28,311,552\n",
      "average_pooling2d_17 | AveragePooling2D | 0 | 0 | (8, 8, 1280) | 81,920 | 0\n",
      "conv2d_282 | Conv2D | (1, 1, 1280, 320) | 409,600 | (8, 8, 320) | 20,480 | 26,214,400\n",
      "batch_normalization_332 | BatchNormalization | 0 | 0 | (8, 8, 384) | 24,576 | 0\n",
      "batch_normalization_333 | BatchNormalization | 0 | 0 | (8, 8, 384) | 24,576 | 0\n",
      "batch_normalization_336 | BatchNormalization | 0 | 0 | (8, 8, 384) | 24,576 | 0\n",
      "batch_normalization_337 | BatchNormalization | 0 | 0 | (8, 8, 384) | 24,576 | 0\n",
      "conv2d_290 | Conv2D | (1, 1, 1280, 192) | 245,760 | (8, 8, 192) | 12,288 | 15,728,640\n",
      "batch_normalization_330 | BatchNormalization | 0 | 0 | (8, 8, 320) | 20,480 | 0\n",
      "activation_281 | Activation | 0 | 0 | (8, 8, 384) | 24,576 | 0\n",
      "activation_282 | Activation | 0 | 0 | (8, 8, 384) | 24,576 | 0\n",
      "activation_285 | Activation | 0 | 0 | (8, 8, 384) | 24,576 | 0\n",
      "activation_286 | Activation | 0 | 0 | (8, 8, 384) | 24,576 | 0\n",
      "batch_normalization_338 | BatchNormalization | 0 | 0 | (8, 8, 192) | 12,288 | 0\n",
      "activation_279 | Activation | 0 | 0 | (8, 8, 320) | 20,480 | 0\n",
      "mixed9_0 | Concatenate | 0 | 0 | (8, 8, 768) | 49,152 | 0\n",
      "concatenate_3 | Concatenate | 0 | 0 | (8, 8, 768) | 49,152 | 0\n",
      "activation_287 | Activation | 0 | 0 | (8, 8, 192) | 12,288 | 0\n",
      "mixed9 | Concatenate | 0 | 0 | (8, 8, 2048) | 131,072 | 0\n",
      "conv2d_295 | Conv2D | (1, 1, 2048, 448) | 917,504 | (8, 8, 448) | 28,672 | 58,720,256\n",
      "batch_normalization_343 | BatchNormalization | 0 | 0 | (8, 8, 448) | 28,672 | 0\n",
      "activation_292 | Activation | 0 | 0 | (8, 8, 448) | 28,672 | 0\n",
      "conv2d_292 | Conv2D | (1, 1, 2048, 384) | 786,432 | (8, 8, 384) | 24,576 | 50,331,648\n",
      "conv2d_296 | Conv2D | (3, 3, 448, 384) | 1,548,288 | (8, 8, 384) | 24,576 | 99,090,432\n",
      "batch_normalization_340 | BatchNormalization | 0 | 0 | (8, 8, 384) | 24,576 | 0\n",
      "batch_normalization_344 | BatchNormalization | 0 | 0 | (8, 8, 384) | 24,576 | 0\n",
      "activation_289 | Activation | 0 | 0 | (8, 8, 384) | 24,576 | 0\n",
      "activation_293 | Activation | 0 | 0 | (8, 8, 384) | 24,576 | 0\n",
      "conv2d_293 | Conv2D | (1, 3, 384, 384) | 442,368 | (8, 8, 384) | 24,576 | 28,311,552\n",
      "conv2d_294 | Conv2D | (3, 1, 384, 384) | 442,368 | (8, 8, 384) | 24,576 | 28,311,552\n",
      "conv2d_297 | Conv2D | (1, 3, 384, 384) | 442,368 | (8, 8, 384) | 24,576 | 28,311,552\n",
      "conv2d_298 | Conv2D | (3, 1, 384, 384) | 442,368 | (8, 8, 384) | 24,576 | 28,311,552\n",
      "average_pooling2d_18 | AveragePooling2D | 0 | 0 | (8, 8, 2048) | 131,072 | 0\n",
      "conv2d_291 | Conv2D | (1, 1, 2048, 320) | 655,360 | (8, 8, 320) | 20,480 | 41,943,040\n",
      "batch_normalization_341 | BatchNormalization | 0 | 0 | (8, 8, 384) | 24,576 | 0\n",
      "batch_normalization_342 | BatchNormalization | 0 | 0 | (8, 8, 384) | 24,576 | 0\n",
      "batch_normalization_345 | BatchNormalization | 0 | 0 | (8, 8, 384) | 24,576 | 0\n",
      "batch_normalization_346 | BatchNormalization | 0 | 0 | (8, 8, 384) | 24,576 | 0\n",
      "conv2d_299 | Conv2D | (1, 1, 2048, 192) | 393,216 | (8, 8, 192) | 12,288 | 25,165,824\n",
      "batch_normalization_339 | BatchNormalization | 0 | 0 | (8, 8, 320) | 20,480 | 0\n",
      "activation_290 | Activation | 0 | 0 | (8, 8, 384) | 24,576 | 0\n",
      "activation_291 | Activation | 0 | 0 | (8, 8, 384) | 24,576 | 0\n",
      "activation_294 | Activation | 0 | 0 | (8, 8, 384) | 24,576 | 0\n",
      "activation_295 | Activation | 0 | 0 | (8, 8, 384) | 24,576 | 0\n",
      "batch_normalization_347 | BatchNormalization | 0 | 0 | (8, 8, 192) | 12,288 | 0\n",
      "activation_288 | Activation | 0 | 0 | (8, 8, 320) | 20,480 | 0\n",
      "mixed9_1 | Concatenate | 0 | 0 | (8, 8, 768) | 49,152 | 0\n",
      "concatenate_4 | Concatenate | 0 | 0 | (8, 8, 768) | 49,152 | 0\n",
      "activation_296 | Activation | 0 | 0 | (8, 8, 192) | 12,288 | 0\n",
      "mixed10 | Concatenate | 0 | 0 | (8, 8, 2048) | 131,072 | 0\n",
      "avg_pool | GlobalAveragePooling2D | 0 | 0 | (2048,) | 2,048 | 0\n",
      "predictions | Dense | (2048, 1000) | 2,048,000 | (1000,) | 1,000 | 2,048,000\n",
      "- | - | - | - | - | - | -\n",
      "- | - | - | Kernel Mem (Total) | - | Output Mem (Total) | FLOPS (Total)\n",
      "Summary | - | - | 23,799,136 | - | 32,554,387 | 5,713,216,096\n",
      "\n",
      "----------------------\n",
      "\n",
      "Model Name: inception_v3\n",
      "Overall FLOPS: 5713 MFLOPS\n",
      "Overall Params: 54 MParams\n",
      "Operational Intensity = 25 FLOPS/Byte\n"
     ]
    }
   ],
   "source": [
    "intensity(InceptionV3(input_shape=(299, 299, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
